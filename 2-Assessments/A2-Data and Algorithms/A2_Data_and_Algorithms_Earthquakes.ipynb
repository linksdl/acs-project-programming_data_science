{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## P4DS: Assignment 2 (Autumn 2020)\n",
    "\n",
    "# Data and Algorithms\n",
    "\n",
    "### Outline\n",
    "\n",
    "* PART I\n",
    "   * Question 1: World cities (10 marks)\n",
    "   * Question 2: Earthquakes   (10 marks)\n",
    "* PART II (in a separate file)\n",
    "   * Question 3: Spell checker (10 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: World Cities\n",
    "\n",
    "In this coursework exercise, you will download data from the provided link and read it in as a `CSV` file using the Pandas data analysis package for Python.\n",
    "\n",
    "The data we will use contains a variety of information about cities from around the world.\n",
    "\n",
    "**Questions Overview**\n",
    "\n",
    "* __Question 1a__ --- Read a `CSV` file into a `pandas` `DataFrame`. __[1 Mark]__\n",
    "\n",
    "* __Question 1b__ --- Generate a list of the largest cities (by population) in the world. __[2 Marks]__\n",
    "\n",
    "* __Question 1c__ --- Find all the cities of a given country. __[2 Marks]__\n",
    "\n",
    "* __Question 1d__ --- Create a DataFrame that contains\n",
    "    the largest cities in a given country. __[3 Marks]__\n",
    "\n",
    "* __Question 1e__ --- Find the total population of people living in cities in a given country. __[4 Marks]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides many useful functions for accessing and manipulating information.\n",
    "For this question you are recommended to use the following:\n",
    "\n",
    "* ```pandas.read_csv(source)``` ---\n",
    "The  [read_csv function](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html#pandas.read_csv) can accept a filename or URL as an argument.\n",
    "\n",
    "* ```df.head()``` ---\n",
    "  For a DataFrame object, ```df```, this method extracts the first 5 rows of data, so you can easily check what the data looks like.\n",
    "  \n",
    "* ```df.describe()``` --- for a DataFrame, ```df```, this method provides a table giving and overview of some basic statistical properties of the DataFrame.\n",
    "\n",
    "Note that the ```head()``` and ```describe()``` methods are actually operations that \n",
    "return a new DataFrame object. If this value is returned by the last line of a cell\n",
    "it will be displayed as a table, but if it is generated elsewhere in the code\n",
    "you will not see any output unless you use the ```display``` function from the\n",
    "```IPython.display``` module.\n",
    "\n",
    "### Question 1a\n",
    "Store the ```worldcities.csv``` file in a Pandas DataFrame. This `CSV` file can be downloaded from the \n",
    "module's [data repository](https://teaching.bb-ai.net/P4DS/data/index.html).\n",
    "\n",
    "More, specifically, you need to modify the following cell in order to set the \n",
    "global variable ```WC_DF``` to a DataFrame containing the information from ```worldcities.csv```. \n",
    "Be sure to keep to the same variable name `WC_DF` for this, otherwise you will \n",
    "break the autograder. **[1 Mark]** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>capital</th>\n",
       "      <th>population</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>35.6850</td>\n",
       "      <td>139.7514</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Tōkyō</td>\n",
       "      <td>primary</td>\n",
       "      <td>35676000.0</td>\n",
       "      <td>1392685764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.6943</td>\n",
       "      <td>-73.9249</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19354922.0</td>\n",
       "      <td>1840034016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mexico City</td>\n",
       "      <td>Mexico City</td>\n",
       "      <td>19.4424</td>\n",
       "      <td>-99.1310</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>MX</td>\n",
       "      <td>MEX</td>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>primary</td>\n",
       "      <td>19028000.0</td>\n",
       "      <td>1484247881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>19.0170</td>\n",
       "      <td>72.8570</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Mahārāshtra</td>\n",
       "      <td>admin</td>\n",
       "      <td>18978000.0</td>\n",
       "      <td>1356226629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-23.5587</td>\n",
       "      <td>-46.6250</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>BR</td>\n",
       "      <td>BRA</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>admin</td>\n",
       "      <td>18845000.0</td>\n",
       "      <td>1076532519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>28.6700</td>\n",
       "      <td>77.2300</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>admin</td>\n",
       "      <td>15926000.0</td>\n",
       "      <td>1356872604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shanghai</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>31.2165</td>\n",
       "      <td>121.4365</td>\n",
       "      <td>China</td>\n",
       "      <td>CN</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>admin</td>\n",
       "      <td>14987000.0</td>\n",
       "      <td>1156073548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>22.4950</td>\n",
       "      <td>88.3247</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>admin</td>\n",
       "      <td>14787000.0</td>\n",
       "      <td>1356060520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>34.1139</td>\n",
       "      <td>-118.4068</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12815475.0</td>\n",
       "      <td>1840020491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>23.7231</td>\n",
       "      <td>90.4086</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BD</td>\n",
       "      <td>BGD</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>primary</td>\n",
       "      <td>12797394.0</td>\n",
       "      <td>1050529279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city   city_ascii      lat       lng        country iso2 iso3  \\\n",
       "0        Tokyo        Tokyo  35.6850  139.7514          Japan   JP  JPN   \n",
       "1     New York     New York  40.6943  -73.9249  United States   US  USA   \n",
       "2  Mexico City  Mexico City  19.4424  -99.1310         Mexico   MX  MEX   \n",
       "3       Mumbai       Mumbai  19.0170   72.8570          India   IN  IND   \n",
       "4    São Paulo    Sao Paulo -23.5587  -46.6250         Brazil   BR  BRA   \n",
       "5        Delhi        Delhi  28.6700   77.2300          India   IN  IND   \n",
       "6     Shanghai     Shanghai  31.2165  121.4365          China   CN  CHN   \n",
       "7      Kolkata      Kolkata  22.4950   88.3247          India   IN  IND   \n",
       "8  Los Angeles  Los Angeles  34.1139 -118.4068  United States   US  USA   \n",
       "9        Dhaka        Dhaka  23.7231   90.4086     Bangladesh   BD  BGD   \n",
       "\n",
       "         admin_name  capital  population          id  \n",
       "0             Tōkyō  primary  35676000.0  1392685764  \n",
       "1          New York      NaN  19354922.0  1840034016  \n",
       "2  Ciudad de México  primary  19028000.0  1484247881  \n",
       "3       Mahārāshtra    admin  18978000.0  1356226629  \n",
       "4         São Paulo    admin  18845000.0  1076532519  \n",
       "5             Delhi    admin  15926000.0  1356872604  \n",
       "6          Shanghai    admin  14987000.0  1156073548  \n",
       "7       West Bengal    admin  14787000.0  1356060520  \n",
       "8        California      NaN  12815475.0  1840020491  \n",
       "9             Dhaka  primary  12797394.0  1050529279  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete Question 1a in this cell.\n",
    "import pandas as pd ## This is the module for creating and manipulating DataFrames\n",
    "import numpy as np\n",
    "\n",
    "# Modify this line to import the data using Pandas\n",
    "WC_DF = pd.read_csv('https://teaching.bb-ai.net/P4DS/data/worldcities.csv', sep=',') \n",
    "WC_DF[:10]\n",
    "# 每个国家包含同一个城市名\n",
    "# 每个大的州或省包含同一个城市名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of  Working with `DataFrame`s\n",
    "\n",
    "To complete these tasks you will need to access and filter a `DataFrame`. \n",
    "The `DataFrame` data structure has many convenient features for extracting and ordering information. Although conceptually it can be thought of as comptuational\n",
    "represention of a table, it is quite a complex data structure and takes a while\n",
    "to master. The following questions can be done with only a small but powerful\n",
    "set of `DataFrame` operations; and the following examples should be useful \n",
    "for coding your answers.\n",
    "\n",
    "#### Accessing DataFrame columns and rows\n",
    "\n",
    "Each column of a `DataFrame` is a list-like object called a\n",
    "`Series`. Elements, and slices of a `Series` can then be accessed in similar\n",
    "fashion to a list. The following illustrates how get the `Series` containing\n",
    "the first 5 elements of the `city` column of `WC_DF`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Tokyo\n",
       "1       New York\n",
       "2    Mexico City\n",
       "3         Mumbai\n",
       "4      São Paulo\n",
       "Name: city, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_cities = WC_DF[\"city\"][:5]   ## selects the first 5 items of the \"city\" column.\n",
    "top_5_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above output, the left hand column of the displayed value of `top_5_cities` \n",
    "shows the index label of each element. One of the differences between a `Series` and an ordinary list is that, whereas a list always has integers for its index labels, a `Series` can have different kinds of values for these. For instance (though there\n",
    "is no reason to do this for the current assignment) we could set the index values to alphabetic letters, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a          Tokyo\n",
       "b       New York\n",
       "c    Mexico City\n",
       "d         Mumbai\n",
       "e      São Paulo\n",
       "Name: city, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_cities.index = list(\"abcde\")\n",
    "top_5_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'b', 'c', 'd', 'e'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_cities.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use ```.values``` to return an `array` of the column values without\n",
    "the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tokyo', 'New York', 'Mexico City', 'Mumbai', 'São Paulo'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WC_DF[\"city\"][:5].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `array` is also a list-like datastructure. It does not have an index. The main difference between a list and an `array` is that the list is optimised for\n",
    "storing large amounts of information and for efficiently applying numerical and\n",
    "other operations to all elements of the array. Hence, `array`s are usually preferred\n",
    "to lists when handling large amounts of information, or when storing numerical\n",
    "vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also easily find the column names of the DataFrame using ```.columns```, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city', 'city_ascii', 'lat', 'lng', 'country', 'iso2', 'iso3',\n",
       "       'admin_name', 'capital', 'population', 'id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WC_DF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The `Index` returned here is yet another type of list-like, object. It is similar to an array,\n",
    "except that it is used for indexing a `Series` or `DataFrame`. You do not usually\n",
    "need to create or deal with `Index` objects directly, since this is done automatically when you create and minipulate `DataFrame`s. So you will normally only see one, when\n",
    "you want to look at the columns or rows of a `DataFrame`. But what you should be\n",
    "aware of, when dealing with `DataFrames`, is that the word _index_ can refer to\n",
    "several different types of thing.\n",
    "\n",
    "In many cases you can treat `Series`, `array` and `Index` objects like lists and if you want to change them to an ordinary list you can just use the `list` operator,\n",
    "as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city',\n",
       " 'city_ascii',\n",
       " 'lat',\n",
       " 'lng',\n",
       " 'country',\n",
       " 'iso2',\n",
       " 'iso3',\n",
       " 'admin_name',\n",
       " 'capital',\n",
       " 'population',\n",
       " 'id']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(WC_DF.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can refer to rows of a `DataFrame` either by the expression `DF.loc[label]`, where `label` is the index label of the row we want, or by `DF.iloc[n]`,\n",
    "where `n` is an `int` giving the position of the row in the `DataFrame`.\n",
    "In the case of `WC_DF`, the labels are integers, so we would get the same result using either. You could test this. You could also see the difference if you try finding a row of `top_5_cities` `DataFrame` defined above, after its index labels have been replaced by letters. In this case you could access rows either using letters, using `loc`, or by `int`s, using `iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city               New York\n",
       "city_ascii         New York\n",
       "lat                 40.6943\n",
       "lng                -73.9249\n",
       "country       United States\n",
       "iso2                     US\n",
       "iso3                    USA\n",
       "admin_name         New York\n",
       "capital                 NaN\n",
       "population      1.93549e+07\n",
       "id               1840034016\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WC_DF.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterrating through the rows of a DataFrame\n",
    "A convenient way of going through the rows of a `DataFrame` to perform some operation i by using the `iterrows` method in a `for` loop. This enables you to get both the index label and the row itself, for each successive row of the `DataFrame`. The following code is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Tokyo 35.685 139.7514\n",
      "1 New York 40.6943 -73.9249\n",
      "2 Mexico City 19.4424 -99.131\n",
      "3 Mumbai 19.017 72.857\n",
      "4 Sao Paulo -23.5587 -46.625\n"
     ]
    }
   ],
   "source": [
    "for i, row in WC_DF.iterrows():\n",
    "    print(i, row['city_ascii'], row['lat'], row['lng'])\n",
    "    if i >3: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the rows of a DataFrame\n",
    "\n",
    "It is easy, and often very useful, to sort the DataFrame by column values using ```.sort_values```, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>capital</th>\n",
       "      <th>population</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>Karukh</td>\n",
       "      <td>Karukh</td>\n",
       "      <td>34.4868</td>\n",
       "      <td>62.5918</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Herāt</td>\n",
       "      <td>minor</td>\n",
       "      <td>17484.0</td>\n",
       "      <td>1004546127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>Kōṯah-ye ‘As̲h̲rō</td>\n",
       "      <td>Kotah-ye `Ashro</td>\n",
       "      <td>34.4500</td>\n",
       "      <td>68.8000</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Wardak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35008.0</td>\n",
       "      <td>1004450357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>Shibirghān</td>\n",
       "      <td>Shibirghan</td>\n",
       "      <td>36.6580</td>\n",
       "      <td>65.7383</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Jowzjān</td>\n",
       "      <td>admin</td>\n",
       "      <td>93241.0</td>\n",
       "      <td>1004805783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>Khōst</td>\n",
       "      <td>Khost</td>\n",
       "      <td>33.3395</td>\n",
       "      <td>69.9204</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Khōst</td>\n",
       "      <td>admin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004919977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5141</th>\n",
       "      <td>Maḩmūd-e Rāqī</td>\n",
       "      <td>Mahmud-e Raqi</td>\n",
       "      <td>35.0167</td>\n",
       "      <td>69.3333</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Kāpīsā</td>\n",
       "      <td>admin</td>\n",
       "      <td>7407.0</td>\n",
       "      <td>1004151943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>Lashkar Gāh</td>\n",
       "      <td>Lashkar Gah</td>\n",
       "      <td>31.5830</td>\n",
       "      <td>64.3600</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Helmand</td>\n",
       "      <td>admin</td>\n",
       "      <td>201546.0</td>\n",
       "      <td>1004765445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>Gardēz</td>\n",
       "      <td>Gardez</td>\n",
       "      <td>33.6001</td>\n",
       "      <td>69.2146</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Paktiyā</td>\n",
       "      <td>admin</td>\n",
       "      <td>103601.0</td>\n",
       "      <td>1004468894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>Maīdān Shahr</td>\n",
       "      <td>Maidan Shahr</td>\n",
       "      <td>34.3956</td>\n",
       "      <td>68.8662</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Wardak</td>\n",
       "      <td>admin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004798735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>Maīmanah</td>\n",
       "      <td>Maimanah</td>\n",
       "      <td>35.9302</td>\n",
       "      <td>64.7701</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Fāryāb</td>\n",
       "      <td>admin</td>\n",
       "      <td>199795.0</td>\n",
       "      <td>1004622920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7399</th>\n",
       "      <td>Andkhōy</td>\n",
       "      <td>Andkhoy</td>\n",
       "      <td>36.9317</td>\n",
       "      <td>65.1015</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Fāryāb</td>\n",
       "      <td>minor</td>\n",
       "      <td>71730.0</td>\n",
       "      <td>1004472345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city       city_ascii      lat      lng      country iso2  \\\n",
       "10235             Karukh           Karukh  34.4868  62.5918  Afghanistan   AF   \n",
       "8527   Kōṯah-ye ‘As̲h̲rō  Kotah-ye `Ashro  34.4500  68.8000  Afghanistan   AF   \n",
       "3341          Shibirghān       Shibirghan  36.6580  65.7383  Afghanistan   AF   \n",
       "6050               Khōst            Khost  33.3395  69.9204  Afghanistan   AF   \n",
       "5141       Maḩmūd-e Rāqī    Mahmud-e Raqi  35.0167  69.3333  Afghanistan   AF   \n",
       "2088         Lashkar Gāh      Lashkar Gah  31.5830  64.3600  Afghanistan   AF   \n",
       "3210              Gardēz           Gardez  33.6001  69.2146  Afghanistan   AF   \n",
       "6249        Maīdān Shahr     Maidan Shahr  34.3956  68.8662  Afghanistan   AF   \n",
       "2105            Maīmanah         Maimanah  35.9302  64.7701  Afghanistan   AF   \n",
       "7399             Andkhōy          Andkhoy  36.9317  65.1015  Afghanistan   AF   \n",
       "\n",
       "      iso3 admin_name capital  population          id  \n",
       "10235  AFG      Herāt   minor     17484.0  1004546127  \n",
       "8527   AFG     Wardak     NaN     35008.0  1004450357  \n",
       "3341   AFG    Jowzjān   admin     93241.0  1004805783  \n",
       "6050   AFG      Khōst   admin         NaN  1004919977  \n",
       "5141   AFG     Kāpīsā   admin      7407.0  1004151943  \n",
       "2088   AFG    Helmand   admin    201546.0  1004765445  \n",
       "3210   AFG    Paktiyā   admin    103601.0  1004468894  \n",
       "6249   AFG     Wardak   admin         NaN  1004798735  \n",
       "2105   AFG     Fāryāb   admin    199795.0  1004622920  \n",
       "7399   AFG     Fāryāb   minor     71730.0  1004472345  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WC_DF.sort_values(by=[\"country\"], ascending=True)[:10] # Sorts countries by alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on __encodings__ of the city name\n",
    "there are two columns that hold the city name. The first column name is `'city'` and\n",
    "the second is `city_ascii`. There are various different ways in which textual\n",
    "information can be encoded into bytes. These days [Unicode characters](https://home.unicode.org/)\n",
    "encoded using [UTF-8](https://en.wikipedia.org/wiki/UTF-8) are pretty standard.\n",
    "But the older [ASCII](https://en.wikipedia.org/wiki/ASCII) code, which uses\n",
    "a single byte per character is still commonly used. Unicode provides a huge\n",
    "variaty of text characters and other symbols, whereas ASCII is quite \n",
    "limited (mainly to characters and symbols found in standard English). \n",
    "But ASCII and is simpler and in \n",
    "some ways easier to deal with than UTF-8. In the following questions you\n",
    "will be asked to use the ASCII version of the city name (from the `city_ascii` column). This mainly just to make you aware that there are different encodings\n",
    "of text strings, but it will also prevent cerain problems that could occur in the\n",
    "Autograder, if different people used different encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering DataFrames\n",
    "By _filtering_ we mean keeping some parts that we want and throwing away others.\n",
    "Typically, we look for rows that match some condition; and the filter condition\n",
    "is often some constraint involving the values for that row in one or more\n",
    "columns.\n",
    "`pandas` `DataFrame`s can  be filtered according values of a column by using a boolean expression, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>capital</th>\n",
       "      <th>population</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>19.0170</td>\n",
       "      <td>72.8570</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Mahārāshtra</td>\n",
       "      <td>admin</td>\n",
       "      <td>18978000.0</td>\n",
       "      <td>1356226629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-23.5587</td>\n",
       "      <td>-46.6250</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>BR</td>\n",
       "      <td>BRA</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>admin</td>\n",
       "      <td>18845000.0</td>\n",
       "      <td>1076532519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>28.6700</td>\n",
       "      <td>77.2300</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>admin</td>\n",
       "      <td>15926000.0</td>\n",
       "      <td>1356872604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shanghai</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>31.2165</td>\n",
       "      <td>121.4365</td>\n",
       "      <td>China</td>\n",
       "      <td>CN</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>admin</td>\n",
       "      <td>14987000.0</td>\n",
       "      <td>1156073548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>22.4950</td>\n",
       "      <td>88.3247</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>admin</td>\n",
       "      <td>14787000.0</td>\n",
       "      <td>1356060520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        city city_ascii      lat       lng country iso2 iso3   admin_name  \\\n",
       "3     Mumbai     Mumbai  19.0170   72.8570   India   IN  IND  Mahārāshtra   \n",
       "4  São Paulo  Sao Paulo -23.5587  -46.6250  Brazil   BR  BRA    São Paulo   \n",
       "5      Delhi      Delhi  28.6700   77.2300   India   IN  IND        Delhi   \n",
       "6   Shanghai   Shanghai  31.2165  121.4365   China   CN  CHN     Shanghai   \n",
       "7    Kolkata    Kolkata  22.4950   88.3247   India   IN  IND  West Bengal   \n",
       "\n",
       "  capital  population          id  \n",
       "3   admin  18978000.0  1356226629  \n",
       "4   admin  18845000.0  1076532519  \n",
       "5   admin  15926000.0  1356872604  \n",
       "6   admin  14987000.0  1156073548  \n",
       "7   admin  14787000.0  1356060520  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_DF = WC_DF[ WC_DF['capital'] == 'admin'] # This keeps only administrative capitals\n",
    "filtered_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way of filtering is a very powerful and useful aspect of `DataFrames`. \n",
    "However, the\n",
    "syntax of the filter operation is rather unusual and a bit difficult to understand.\n",
    "\n",
    "What is happening can be explained by these steps in the way a filter expression\n",
    "is evaluated:\n",
    "*  `DF['label']` (where `DF` is any `DataFrame`), gives a `Series` corresponding\n",
    "    to    the `'label'` column of `DF.\n",
    "    \n",
    "*  `a_series == val` is a special use of `==`. When a Boolean operator\n",
    "    (such `==`, `<` etc.) is applied to a `Series` object\n",
    "   the result is actually a `Series` of Boolean values (not a single Boolean).\n",
    "   The new `Series` obtained will have the value `True` for each element where\n",
    "   the original `Series` satisfies `element == val`, and `False` for the rest.\n",
    "   \n",
    "* `DF[ bool_series ]`, is a special kind of slice-like operation, where a boolean\n",
    "   series is given as a selection argument to the `DataFrame`. It will return \n",
    "   a new DF, containing all the rows of `DF` for which `bool_series` has the \n",
    "   value `True`. (These rows can be quickly found because the `DataFrame` and\n",
    "   the Boolean series both have the same `Index`.)\n",
    "   \n",
    "You do not necessarily need to follow all of that precise desciption of filtering\n",
    "but it will be extremely helpful if you are able to construct filtering\n",
    "operations similar to the above example. You will see another example below,\n",
    "in relation to the earthquake data you will be processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1b \n",
    "Write a function `find_largest_cites` that takes an `int` argument `n`  and uses the\n",
    "pandas DataFrame WC_DF to derive and return a `list` of the `n` largest cities, in terms of population size. The list should contain the `ascii` names of the cities in order of population size, with the largest first.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokyo', 'New York', 'Mexico City', 'Mumbai', 'Sao Paulo', 'Delhi']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1b answer cell\n",
    "def find_largest_cities(n):\n",
    "    \n",
    "    top_n_largest_cities = []\n",
    "    \n",
    "    # if n is None or n less than 1, should be return []\n",
    "    if n == None or n < 1:\n",
    "        return []\n",
    "\n",
    "    # Modify to return a list of the n cities with the largest population   \n",
    "    df = WC_DF.sort_values(by=[\"population\"], ascending=False) # Sorts cities by population\n",
    "    top_n_largest_cities = list(df[:n]['city_ascii'])\n",
    "    return top_n_largest_cities\n",
    "\n",
    "city = find_largest_cities(6)\n",
    "city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE:__ In answering __1b__ you may assume that no two cities have exactly the same population, which is almost but not quite certain, when dealing with large numbers like this. But, of course, when dealing with quantites where multiple data records could have the same value, we need to be careful, because this may not be the case.\n",
    "For example, if we are interested in what equipement students own, we might think it would be informative\n",
    "to find 'the top 10 students owning the most laptops'. In this case there could be: 1 student with 3 laptops, 23 students with 2 laptops, 160 with 1 laptop and 3 who do not own a laptop. In such a case it is not meaningful to pick the 'top 10' in terms of laptop ownership. A similar problem could potentiall occur with the earthquake data that we will look at later, because the earthquake magnitudes are only recorded to 1 decimal place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1c\n",
    "Define a function that returns a `list` _in alphabetical order_ of all the cities of a certain country. Make sure this function is case insensitive to the string input and that the output list contains\n",
    "the `ascii` version of the city names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aksu', 'Altay', 'Anda', 'Ankang', 'Anlu', 'Anqing']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1c answer cell\n",
    "def find_cities_in_country(country):\n",
    "    \"\"\"country is a string input\"\"\"\n",
    "    # Edit this function to return an array of the cities belonging to given country\n",
    "    list_cities_of_country = []\n",
    "    \n",
    "    if country == None:\n",
    "        return []\n",
    "    else:\n",
    "        country = country.lower().title()\n",
    "    \n",
    "    df = WC_DF[WC_DF['country'] == country].sort_values(by=[\"city_ascii\"], ascending=True)\n",
    "    df = df['city_ascii']\n",
    "    list_cities_of_country = list(dict.fromkeys(list(df)))\n",
    "    return list_cities_of_country\n",
    "\n",
    "cites = find_cities_in_country('China')\n",
    "cites[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1d\n",
    "Use the function you created in Question 1c and some of code from Question 1b to create a new function that  returns a `DataFrame` containing `n` largest cities (by population) of a given country, in descending order of population (i.e. highest population first).\n",
    "\n",
    "__Note:__ For this question, you must return a `DataFrame` (not a list). You could test this function with a command such as ```display(largest_cities(5, japan))```, which should show a table of city data for these\n",
    "cities. Note also that the `display` function produces the same output as you get from its argument expression when it is on its own as the last line of a code cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>capital</th>\n",
       "      <th>population</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>35.685</td>\n",
       "      <td>139.7514</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Tōkyō</td>\n",
       "      <td>primary</td>\n",
       "      <td>35676000.0</td>\n",
       "      <td>1392685764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ōsaka</td>\n",
       "      <td>Osaka</td>\n",
       "      <td>34.750</td>\n",
       "      <td>135.4601</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Ōsaka</td>\n",
       "      <td>admin</td>\n",
       "      <td>11294000.0</td>\n",
       "      <td>1392419823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Yokohama</td>\n",
       "      <td>Yokohama</td>\n",
       "      <td>35.320</td>\n",
       "      <td>139.5800</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Kanagawa</td>\n",
       "      <td>admin</td>\n",
       "      <td>3697894.0</td>\n",
       "      <td>1392118339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Nagoya</td>\n",
       "      <td>Nagoya</td>\n",
       "      <td>35.155</td>\n",
       "      <td>136.9150</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Aichi</td>\n",
       "      <td>admin</td>\n",
       "      <td>3230000.0</td>\n",
       "      <td>1392407472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Fukuoka</td>\n",
       "      <td>Fukuoka</td>\n",
       "      <td>33.595</td>\n",
       "      <td>130.4100</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Fukuoka</td>\n",
       "      <td>admin</td>\n",
       "      <td>2792000.0</td>\n",
       "      <td>1392576294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Sapporo</td>\n",
       "      <td>Sapporo</td>\n",
       "      <td>43.075</td>\n",
       "      <td>141.3400</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Hokkaidō</td>\n",
       "      <td>admin</td>\n",
       "      <td>2544000.0</td>\n",
       "      <td>1392000195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city city_ascii     lat       lng country iso2 iso3 admin_name  \\\n",
       "0       Tokyo      Tokyo  35.685  139.7514   Japan   JP  JPN      Tōkyō   \n",
       "14      Ōsaka      Osaka  34.750  135.4601   Japan   JP  JPN      Ōsaka   \n",
       "82   Yokohama   Yokohama  35.320  139.5800   Japan   JP  JPN   Kanagawa   \n",
       "103    Nagoya     Nagoya  35.155  136.9150   Japan   JP  JPN      Aichi   \n",
       "133   Fukuoka    Fukuoka  33.595  130.4100   Japan   JP  JPN    Fukuoka   \n",
       "156   Sapporo    Sapporo  43.075  141.3400   Japan   JP  JPN   Hokkaidō   \n",
       "\n",
       "     capital  population          id  \n",
       "0    primary  35676000.0  1392685764  \n",
       "14     admin  11294000.0  1392419823  \n",
       "82     admin   3697894.0  1392118339  \n",
       "103    admin   3230000.0  1392407472  \n",
       "133    admin   2792000.0  1392576294  \n",
       "156    admin   2544000.0  1392000195  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete question 1d in this cell\n",
    "def largest_cities(n, country): # country is a string argument\n",
    "    \n",
    "    # Edit this function to return the largest cities of a country\n",
    "    if country == None or country == ' ' or n == None or n < 1:\n",
    "        return None\n",
    "    else:\n",
    "        country = country.lower().title()\n",
    "    \n",
    "    \n",
    "    df = WC_DF[WC_DF['country'] == country].sort_values(by=[\"population\"], ascending=False)\n",
    "    cities_of_country = find_cities_in_country(country)\n",
    "    df = df[:n]\n",
    "    # display(df)\n",
    "    return df\n",
    "       \n",
    "largest_cities(6, 'Japan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1e\n",
    "Create a function that given a country name, returns an `int` which is the total population of \n",
    "that country living in the cities in that country, as given in `WC_DF`. \n",
    "\n",
    "**Hints:** \n",
    "* Use the function you created in Question 1c to find the cities of a country.\n",
    "* You can ignore cities for which no population value is recorded in `WC_DF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204338075"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Question 1e Answer Code Cell\n",
    "def country_city_population(country):\n",
    "    \n",
    "    numbers_of_population = 0\n",
    "    if country == None or country == ' ':\n",
    "        return None\n",
    "    else:\n",
    "        country = country.lower().title()\n",
    "    \n",
    "    df = WC_DF[WC_DF['country'] == country]\n",
    "    df = df[df['population'] >= 0]\n",
    "    df = df.groupby(['city_ascii','admin_name'])['population'].sum()   \n",
    "    for row in df.items():\n",
    "        numbers_of_population += int(row[1]) \n",
    "        \n",
    "    return numbers_of_population\n",
    "\n",
    "num = country_city_population('India')\n",
    "num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Earthquakes - Web Access and Pandas DataFrames\n",
    "\n",
    "In this coursework exercise, you will learn how to download live information\n",
    "from the web and procress it using the Pandas data analysis package for Python.\n",
    "\n",
    "The data we will use as an example is from the \n",
    "[United States Geological Survey (USGS)](https://www.usgs.gov/), which \n",
    "provides a wide range of geographic and geological information and data.\n",
    "We shall be using their data relating to seismological \n",
    "events (i.e. Earthquakes) from around the world, which is published in the \n",
    "form of continually updated CSV files.\n",
    "\n",
    "Questions Overview\n",
    "\n",
    "* __Q2a__ --- Initialise a Pandas DataFrame by downloading earthquake data from the web. __[1 mark]__\n",
    "* __Q2b__ --- Find earthquakes of a given magnitude or higher.           __[2 marks]__\n",
    "* __Q2c__ --- Make a DataFrame showing the most powerful quakes          __[3 marks]__\n",
    "* __Q2d__ --- Identify large cities endangered by powerful earthquakes   __[4 makrs]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2a: Read in data file\n",
    "Read earthquake data from the USGS live feed CSV ```all_day.csv``` into a Pandas DataFrame.\n",
    "The data can be obtained directly from  http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_day.csv and read into a Pandas DataFrame.\n",
    "\n",
    "__Note:__ For this question you do not need to download and save the file ```all_day.csv```. It should\n",
    "be loaded directly from the web feed. However, while testing, if you have no internet connection or\n",
    "a bad connection you could download a copy of the file. But remember to put it back to downloading\n",
    "the current one before you submit. Note also that ```all_day.csv``` is a live file, which lists\n",
    "quakes recorded during the past 24 hours, and is updated every minute, so of course,\n",
    "you will not always get the same file or the same results. More information about this and other\n",
    "earthquake feeds provided by USGS can be found [here](https://earthquake.usgs.gov/earthquakes/feed/v1.0/csv.php)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2a answer code cell\n",
    "import pandas   ## This is the module for creating and manupulating DataFrames\n",
    "\n",
    "# Here we have assigned the url of the quake datasource to the global variable \n",
    "# 'QUAKE_SOURCE' for your convenience.\n",
    "QUAKE_SOURCE = ( \"http://earthquake.usgs.gov/\" +\n",
    "                 \"earthquakes/feed/v1.0/summary/all_day.csv\" )\n",
    "# Modify this line to import the data using Pandas\n",
    "QUAKE_DF = pandas.read_csv(QUAKE_SOURCE, sep=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can use the following cell to test if you have read the quake data into `QUAKE_DF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-16T21:08:09.599Z</td>\n",
       "      <td>58.7157</td>\n",
       "      <td>-153.007500</td>\n",
       "      <td>63.70</td>\n",
       "      <td>2.10</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T21:12:45.668Z</td>\n",
       "      <td>73 km N of Aleneva, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automatic</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-16T21:01:43.630Z</td>\n",
       "      <td>33.5890</td>\n",
       "      <td>-116.595333</td>\n",
       "      <td>13.15</td>\n",
       "      <td>1.05</td>\n",
       "      <td>ml</td>\n",
       "      <td>28.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T21:05:25.377Z</td>\n",
       "      <td>8km ENE of Anza, CA</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.116</td>\n",
       "      <td>23.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>ci</td>\n",
       "      <td>ci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-16T21:01:38.217Z</td>\n",
       "      <td>64.2672</td>\n",
       "      <td>-149.908800</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1.50</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.74</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T21:08:35.100Z</td>\n",
       "      <td>35 km W of Clear, Alaska, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automatic</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-16T20:41:29.830Z</td>\n",
       "      <td>38.1768</td>\n",
       "      <td>-117.834500</td>\n",
       "      <td>4.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>ml</td>\n",
       "      <td>23.0</td>\n",
       "      <td>97.74</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T20:58:24.994Z</td>\n",
       "      <td>33 km SE of Mina, Nevada</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-16T20:29:56.262Z</td>\n",
       "      <td>54.5255</td>\n",
       "      <td>-159.696700</td>\n",
       "      <td>25.02</td>\n",
       "      <td>3.70</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204.00</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T20:56:34.040Z</td>\n",
       "      <td>103 km SSE of Sand Point, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>4.90</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.066</td>\n",
       "      <td>30.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  latitude   longitude  depth   mag magType   nst  \\\n",
       "0  2020-11-16T21:08:09.599Z   58.7157 -153.007500  63.70  2.10      ml   NaN   \n",
       "1  2020-11-16T21:01:43.630Z   33.5890 -116.595333  13.15  1.05      ml  28.0   \n",
       "2  2020-11-16T21:01:38.217Z   64.2672 -149.908800   8.20  1.50      ml   NaN   \n",
       "3  2020-11-16T20:41:29.830Z   38.1768 -117.834500   4.60  1.60      ml  23.0   \n",
       "4  2020-11-16T20:29:56.262Z   54.5255 -159.696700  25.02  3.70      ml   NaN   \n",
       "\n",
       "      gap      dmin   rms  ...                   updated  \\\n",
       "0     NaN       NaN  0.63  ...  2020-11-16T21:12:45.668Z   \n",
       "1   78.00  0.009175  0.21  ...  2020-11-16T21:05:25.377Z   \n",
       "2     NaN       NaN  0.74  ...  2020-11-16T21:08:35.100Z   \n",
       "3   97.74  0.022000  0.12  ...  2020-11-16T20:58:24.994Z   \n",
       "4  204.00  0.312000  0.39  ...  2020-11-16T20:56:34.040Z   \n",
       "\n",
       "                              place        type horizontalError depthError  \\\n",
       "0        73 km N of Aleneva, Alaska  earthquake             NaN       0.90   \n",
       "1               8km ENE of Anza, CA  earthquake            0.35       0.52   \n",
       "2  35 km W of Clear, Alaska, Alaska  earthquake             NaN       0.30   \n",
       "3          33 km SE of Mina, Nevada  earthquake             NaN       0.80   \n",
       "4  103 km SSE of Sand Point, Alaska  earthquake            4.90       8.30   \n",
       "\n",
       "   magError  magNst     status  locationSource magSource  \n",
       "0       NaN     NaN  automatic              ak        ak  \n",
       "1     0.116    23.0  automatic              ci        ci  \n",
       "2       NaN     NaN  automatic              ak        ak  \n",
       "3       NaN     NaN  automatic              nn        nn  \n",
       "4     0.066    30.0   reviewed              us        us  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## If QUAKE_DF is a DataFrame, show the first 5 rows\n",
    "if type(QUAKE_DF) == pandas.DataFrame:\n",
    "    display(QUAKE_DF.head())\n",
    "else:\n",
    "    print(\"QUAKE_DF is not a DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More examples of useful `pandas` functions\n",
    "\n",
    "Here we show you some more pandas functions that you may find useful in this exercise. \n",
    "\n",
    "As we have seen, versatile filtering and sorting capabilities are provided by pandas. To get more understanding of these, you should look at tutorials of using Pandas DataFrames. But the following example illustrates how you can find and display quakes whose depth is greater than or equal to a given threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of quakes of depth 150 or deeper: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2020-11-16T16:41:20.721Z</td>\n",
       "      <td>-23.9089</td>\n",
       "      <td>-67.0683</td>\n",
       "      <td>229.54</td>\n",
       "      <td>4.5</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.395</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T17:09:09.040Z</td>\n",
       "      <td>83 km WNW of San Antonio de los Cobres, Argentina</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>11.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.222</td>\n",
       "      <td>8.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2020-11-15T23:19:03.503Z</td>\n",
       "      <td>-24.3285</td>\n",
       "      <td>-67.4556</td>\n",
       "      <td>198.96</td>\n",
       "      <td>4.8</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.522</td>\n",
       "      <td>0.68</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-15T23:34:12.040Z</td>\n",
       "      <td>116 km W of San Antonio de los Cobres, Argentina</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>8.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.278</td>\n",
       "      <td>4.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2020-11-15T22:34:50.138Z</td>\n",
       "      <td>59.9569</td>\n",
       "      <td>-154.1727</td>\n",
       "      <td>189.20</td>\n",
       "      <td>2.4</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-15T22:45:24.501Z</td>\n",
       "      <td>19 km N of Pedro Bay, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automatic</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2020-11-16T12:36:11.434Z</td>\n",
       "      <td>-21.3641</td>\n",
       "      <td>170.5557</td>\n",
       "      <td>151.84</td>\n",
       "      <td>4.7</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.355</td>\n",
       "      <td>0.70</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T13:46:13.040Z</td>\n",
       "      <td>241 km SSE of Isangel, Vanuatu</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.081</td>\n",
       "      <td>49.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time  latitude  longitude   depth  mag magType  nst  \\\n",
       "61   2020-11-16T16:41:20.721Z  -23.9089   -67.0683  229.54  4.5      mb  NaN   \n",
       "305  2020-11-15T23:19:03.503Z  -24.3285   -67.4556  198.96  4.8      mb  NaN   \n",
       "318  2020-11-15T22:34:50.138Z   59.9569  -154.1727  189.20  2.4      ml  NaN   \n",
       "115  2020-11-16T12:36:11.434Z  -21.3641   170.5557  151.84  4.7      mb  NaN   \n",
       "\n",
       "       gap   dmin   rms  ...                   updated  \\\n",
       "61   143.0  1.395  0.66  ...  2020-11-16T17:09:09.040Z   \n",
       "305   71.0  1.522  0.68  ...  2020-11-15T23:34:12.040Z   \n",
       "318    NaN    NaN  0.76  ...  2020-11-15T22:45:24.501Z   \n",
       "115  116.0  2.355  0.70  ...  2020-11-16T13:46:13.040Z   \n",
       "\n",
       "                                                 place        type  \\\n",
       "61   83 km WNW of San Antonio de los Cobres, Argentina  earthquake   \n",
       "305   116 km W of San Antonio de los Cobres, Argentina  earthquake   \n",
       "318                       19 km N of Pedro Bay, Alaska  earthquake   \n",
       "115                     241 km SSE of Isangel, Vanuatu  earthquake   \n",
       "\n",
       "    horizontalError depthError  magError  magNst     status  locationSource  \\\n",
       "61             11.6       10.0     0.222     8.0   reviewed              us   \n",
       "305             8.1       13.0     0.278     4.0   reviewed              us   \n",
       "318             NaN        1.3       NaN     NaN  automatic              ak   \n",
       "115             4.0        7.4     0.081    49.0   reviewed              us   \n",
       "\n",
       "    magSource  \n",
       "61         us  \n",
       "305        us  \n",
       "318        ak  \n",
       "115        us  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_deep_quakes( depth ):\n",
    "    # make deep_quakes DataFrame by selecting rows from QUAKE_DF\n",
    "    deep_quakes = QUAKE_DF[ QUAKE_DF[\"depth\"] >= depth ]  ## This is how you select rows by a condition\n",
    "                                                          ## on one of the column values.\n",
    "        \n",
    "    print(\"Number of quakes of depth {} or deeper:\".format(depth), \n",
    "           len(deep_quakes.index))     ## This finds the number of rows of the deep_quakes DataFrame\n",
    "    \n",
    "    display(deep_quakes.sort_values(\"depth\", ascending=False))  ## Sort by descending depth value\n",
    "    \n",
    "show_deep_quakes(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find ```max``` and ```min``` values in a column. Eg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229.54"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUAKE_DF[\"depth\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUAKE_DF[\"mag\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2b: Find Powerful Quakes\n",
    "\n",
    "Write a function `powerful_quakes` that takes a numerical argument and returns a `DataFrame` including\n",
    "all the quakes in `QUAKE_DF` that have a magnitude greater than or equal to the given argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-11-16T20:18:34.076Z</td>\n",
       "      <td>-28.4228</td>\n",
       "      <td>-71.0898</td>\n",
       "      <td>44.10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.70</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T20:56:10.040Z</td>\n",
       "      <td>36 km WNW of Vallenar, Chile</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.039</td>\n",
       "      <td>207.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-11-16T19:23:24.606Z</td>\n",
       "      <td>-3.0341</td>\n",
       "      <td>129.8255</td>\n",
       "      <td>31.88</td>\n",
       "      <td>4.3</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.422</td>\n",
       "      <td>0.87</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T21:03:35.040Z</td>\n",
       "      <td>106 km ENE of Amahai, Indonesia</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>8.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.126</td>\n",
       "      <td>18.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020-11-16T18:37:48.196Z</td>\n",
       "      <td>21.6959</td>\n",
       "      <td>120.9516</td>\n",
       "      <td>17.78</td>\n",
       "      <td>4.7</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.122</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T19:04:23.040Z</td>\n",
       "      <td>40 km SSE of Hengchun, Taiwan</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.065</td>\n",
       "      <td>72.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-11-16T17:18:16.546Z</td>\n",
       "      <td>59.7148</td>\n",
       "      <td>-138.9320</td>\n",
       "      <td>6.60</td>\n",
       "      <td>4.2</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T19:38:54.270Z</td>\n",
       "      <td>48 km ENE of Yakutat, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2020-11-16T16:41:20.721Z</td>\n",
       "      <td>-23.9089</td>\n",
       "      <td>-67.0683</td>\n",
       "      <td>229.54</td>\n",
       "      <td>4.5</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.395</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T17:09:09.040Z</td>\n",
       "      <td>83 km WNW of San Antonio de los Cobres, Argentina</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>11.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.222</td>\n",
       "      <td>8.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2020-11-16T15:08:13.140Z</td>\n",
       "      <td>27.6372</td>\n",
       "      <td>129.9391</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.684</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T17:14:03.171Z</td>\n",
       "      <td>92 km SSE of Naze, Japan</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.051</td>\n",
       "      <td>124.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2020-11-16T14:22:46.783Z</td>\n",
       "      <td>-32.4386</td>\n",
       "      <td>-71.4912</td>\n",
       "      <td>67.98</td>\n",
       "      <td>4.2</td>\n",
       "      <td>mwr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T17:53:02.734Z</td>\n",
       "      <td>24 km W of La Ligua, Chile</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>6.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>guc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2020-11-16T13:59:20.585Z</td>\n",
       "      <td>4.7095</td>\n",
       "      <td>-76.4865</td>\n",
       "      <td>62.89</td>\n",
       "      <td>4.8</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.753</td>\n",
       "      <td>0.79</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T17:43:09.833Z</td>\n",
       "      <td>18 km ENE of Sipí, Colombia</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>7.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.088</td>\n",
       "      <td>42.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2020-11-16T13:48:25.995Z</td>\n",
       "      <td>0.3757</td>\n",
       "      <td>126.3594</td>\n",
       "      <td>41.72</td>\n",
       "      <td>4.6</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.081</td>\n",
       "      <td>0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T14:44:23.040Z</td>\n",
       "      <td>122 km WSW of Ternate, Indonesia</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.112</td>\n",
       "      <td>24.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2020-11-16T13:42:16.901Z</td>\n",
       "      <td>-10.9304</td>\n",
       "      <td>164.4230</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5.1</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.648</td>\n",
       "      <td>0.61</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T14:33:58.040Z</td>\n",
       "      <td>151 km W of Lata, Solomon Islands</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.058</td>\n",
       "      <td>97.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2020-11-16T12:36:11.434Z</td>\n",
       "      <td>-21.3641</td>\n",
       "      <td>170.5557</td>\n",
       "      <td>151.84</td>\n",
       "      <td>4.7</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.355</td>\n",
       "      <td>0.70</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T13:46:13.040Z</td>\n",
       "      <td>241 km SSE of Isangel, Vanuatu</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.081</td>\n",
       "      <td>49.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2020-11-16T11:21:17.830Z</td>\n",
       "      <td>-62.3824</td>\n",
       "      <td>-58.4868</td>\n",
       "      <td>10.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T14:59:25.040Z</td>\n",
       "      <td>South Shetland Islands</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.174</td>\n",
       "      <td>11.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2020-11-16T07:51:06.034Z</td>\n",
       "      <td>-15.8905</td>\n",
       "      <td>-173.6473</td>\n",
       "      <td>110.34</td>\n",
       "      <td>4.6</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.0</td>\n",
       "      <td>4.598</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T08:30:30.040Z</td>\n",
       "      <td>17 km ENE of Hihifo, Tonga</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>12.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.038</td>\n",
       "      <td>208.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2020-11-16T07:19:11.946Z</td>\n",
       "      <td>21.9599</td>\n",
       "      <td>121.4559</td>\n",
       "      <td>62.13</td>\n",
       "      <td>4.8</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.72</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T07:38:29.040Z</td>\n",
       "      <td>73 km E of Hengchun, Taiwan</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.069</td>\n",
       "      <td>65.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2020-11-16T05:34:45.285Z</td>\n",
       "      <td>-34.3339</td>\n",
       "      <td>-72.6262</td>\n",
       "      <td>10.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>mwr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T13:03:20.040Z</td>\n",
       "      <td>112 km N of Constitución, Chile</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>guc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2020-11-16T00:28:04.247Z</td>\n",
       "      <td>-5.9008</td>\n",
       "      <td>130.8801</td>\n",
       "      <td>115.00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141.0</td>\n",
       "      <td>3.261</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T00:50:30.040Z</td>\n",
       "      <td>209 km W of Tual, Indonesia</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>7.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.179</td>\n",
       "      <td>9.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2020-11-15T23:19:03.503Z</td>\n",
       "      <td>-24.3285</td>\n",
       "      <td>-67.4556</td>\n",
       "      <td>198.96</td>\n",
       "      <td>4.8</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.522</td>\n",
       "      <td>0.68</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-15T23:34:12.040Z</td>\n",
       "      <td>116 km W of San Antonio de los Cobres, Argentina</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>8.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.278</td>\n",
       "      <td>4.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2020-11-15T22:37:43.739Z</td>\n",
       "      <td>8.7425</td>\n",
       "      <td>126.2805</td>\n",
       "      <td>44.51</td>\n",
       "      <td>6.0</td>\n",
       "      <td>mww</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.801</td>\n",
       "      <td>1.02</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T17:06:40.040Z</td>\n",
       "      <td>7 km SSW of Marihatag, Philippines</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.040</td>\n",
       "      <td>60.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>2020-11-15T21:54:47.401Z</td>\n",
       "      <td>-28.0254</td>\n",
       "      <td>-65.9637</td>\n",
       "      <td>31.24</td>\n",
       "      <td>4.2</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.0</td>\n",
       "      <td>3.052</td>\n",
       "      <td>0.69</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T05:29:42.040Z</td>\n",
       "      <td>13 km SW of Los Varela, Argentina</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.235</td>\n",
       "      <td>5.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2020-11-15T21:14:21.393Z</td>\n",
       "      <td>54.5496</td>\n",
       "      <td>-159.7617</td>\n",
       "      <td>35.00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>mwr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.97</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T05:16:55.993Z</td>\n",
       "      <td>99 km SSE of Sand Point, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>40.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time  latitude  longitude   depth  mag magType  nst  \\\n",
       "6    2020-11-16T20:18:34.076Z  -28.4228   -71.0898   44.10  5.0      mb  NaN   \n",
       "19   2020-11-16T19:23:24.606Z   -3.0341   129.8255   31.88  4.3      mb  NaN   \n",
       "33   2020-11-16T18:37:48.196Z   21.6959   120.9516   17.78  4.7      mb  NaN   \n",
       "49   2020-11-16T17:18:16.546Z   59.7148  -138.9320    6.60  4.2      ml  NaN   \n",
       "61   2020-11-16T16:41:20.721Z  -23.9089   -67.0683  229.54  4.5      mb  NaN   \n",
       "80   2020-11-16T15:08:13.140Z   27.6372   129.9391   10.00  5.0      mb  NaN   \n",
       "90   2020-11-16T14:22:46.783Z  -32.4386   -71.4912   67.98  4.2     mwr  NaN   \n",
       "93   2020-11-16T13:59:20.585Z    4.7095   -76.4865   62.89  4.8      mb  NaN   \n",
       "96   2020-11-16T13:48:25.995Z    0.3757   126.3594   41.72  4.6      mb  NaN   \n",
       "98   2020-11-16T13:42:16.901Z  -10.9304   164.4230   10.00  5.1      mb  NaN   \n",
       "115  2020-11-16T12:36:11.434Z  -21.3641   170.5557  151.84  4.7      mb  NaN   \n",
       "132  2020-11-16T11:21:17.830Z  -62.3824   -58.4868   10.00  4.7      mb  NaN   \n",
       "192  2020-11-16T07:51:06.034Z  -15.8905  -173.6473  110.34  4.6      mb  NaN   \n",
       "200  2020-11-16T07:19:11.946Z   21.9599   121.4559   62.13  4.8      mb  NaN   \n",
       "226  2020-11-16T05:34:45.285Z  -34.3339   -72.6262   10.00  4.5     mwr  NaN   \n",
       "289  2020-11-16T00:28:04.247Z   -5.9008   130.8801  115.00  4.4      mb  NaN   \n",
       "305  2020-11-15T23:19:03.503Z  -24.3285   -67.4556  198.96  4.8      mb  NaN   \n",
       "315  2020-11-15T22:37:43.739Z    8.7425   126.2805   44.51  6.0     mww  NaN   \n",
       "325  2020-11-15T21:54:47.401Z  -28.0254   -65.9637   31.24  4.2      mb  NaN   \n",
       "333  2020-11-15T21:14:21.393Z   54.5496  -159.7617   35.00  4.3     mwr  NaN   \n",
       "\n",
       "       gap   dmin   rms  ...                   updated  \\\n",
       "6    115.0  0.217  0.70  ...  2020-11-16T20:56:10.040Z   \n",
       "19   106.0  2.422  0.87  ...  2020-11-16T21:03:35.040Z   \n",
       "33    82.0  1.122  1.16  ...  2020-11-16T19:04:23.040Z   \n",
       "49     NaN    NaN  0.82  ...  2020-11-16T19:38:54.270Z   \n",
       "61   143.0  1.395  0.66  ...  2020-11-16T17:09:09.040Z   \n",
       "80    82.0  1.684  0.80  ...  2020-11-16T17:14:03.171Z   \n",
       "90   164.0  0.589  0.30  ...  2020-11-16T17:53:02.734Z   \n",
       "93    95.0  1.753  0.79  ...  2020-11-16T17:43:09.833Z   \n",
       "96    75.0  1.081  0.55  ...  2020-11-16T14:44:23.040Z   \n",
       "98    85.0  4.648  0.61  ...  2020-11-16T14:33:58.040Z   \n",
       "115  116.0  2.355  0.70  ...  2020-11-16T13:46:13.040Z   \n",
       "132   83.0  0.167  0.46  ...  2020-11-16T14:59:25.040Z   \n",
       "192  124.0  4.598  0.39  ...  2020-11-16T08:30:30.040Z   \n",
       "200  120.0  0.922  0.72  ...  2020-11-16T07:38:29.040Z   \n",
       "226  151.0  0.885  0.59  ...  2020-11-16T13:03:20.040Z   \n",
       "289  141.0  3.261  0.91  ...  2020-11-16T00:50:30.040Z   \n",
       "305   71.0  1.522  0.68  ...  2020-11-15T23:34:12.040Z   \n",
       "315   33.0  1.801  1.02  ...  2020-11-16T17:06:40.040Z   \n",
       "325  134.0  3.052  0.69  ...  2020-11-16T05:29:42.040Z   \n",
       "333  174.0  0.299  0.97  ...  2020-11-16T05:16:55.993Z   \n",
       "\n",
       "                                                 place        type  \\\n",
       "6                         36 km WNW of Vallenar, Chile  earthquake   \n",
       "19                     106 km ENE of Amahai, Indonesia  earthquake   \n",
       "33                       40 km SSE of Hengchun, Taiwan  earthquake   \n",
       "49                        48 km ENE of Yakutat, Alaska  earthquake   \n",
       "61   83 km WNW of San Antonio de los Cobres, Argentina  earthquake   \n",
       "80                            92 km SSE of Naze, Japan  earthquake   \n",
       "90                          24 km W of La Ligua, Chile  earthquake   \n",
       "93                         18 km ENE of Sipí, Colombia  earthquake   \n",
       "96                    122 km WSW of Ternate, Indonesia  earthquake   \n",
       "98                   151 km W of Lata, Solomon Islands  earthquake   \n",
       "115                     241 km SSE of Isangel, Vanuatu  earthquake   \n",
       "132                             South Shetland Islands  earthquake   \n",
       "192                         17 km ENE of Hihifo, Tonga  earthquake   \n",
       "200                        73 km E of Hengchun, Taiwan  earthquake   \n",
       "226                    112 km N of Constitución, Chile  earthquake   \n",
       "289                        209 km W of Tual, Indonesia  earthquake   \n",
       "305   116 km W of San Antonio de los Cobres, Argentina  earthquake   \n",
       "315                 7 km SSW of Marihatag, Philippines  earthquake   \n",
       "325                  13 km SW of Los Varela, Argentina  earthquake   \n",
       "333                    99 km SSE of Sand Point, Alaska  earthquake   \n",
       "\n",
       "    horizontalError depthError  magError  magNst    status  locationSource  \\\n",
       "6               4.6        3.2     0.039   207.0  reviewed              us   \n",
       "19              8.6        7.2     0.126    18.0  reviewed              us   \n",
       "33              7.3        4.8     0.065    72.0  reviewed              us   \n",
       "49              NaN        0.4       NaN     NaN  reviewed              ak   \n",
       "61             11.6       10.0     0.222     8.0  reviewed              us   \n",
       "80              5.9        1.9     0.051   124.0  reviewed              us   \n",
       "90              6.3        9.1       NaN     NaN  reviewed              us   \n",
       "93              7.1        8.6     0.088    42.0  reviewed              us   \n",
       "96              7.7        7.6     0.112    24.0  reviewed              us   \n",
       "98             10.2        1.8     0.058    97.0  reviewed              us   \n",
       "115             4.0        7.4     0.081    49.0  reviewed              us   \n",
       "132             3.4        1.9     0.174    11.0  reviewed              us   \n",
       "192            12.9        7.5     0.038   208.0  reviewed              us   \n",
       "200             8.0        4.8     0.069    65.0  reviewed              us   \n",
       "226             4.3        1.9       NaN     NaN  reviewed              us   \n",
       "289             7.9       11.2     0.179     9.0  reviewed              us   \n",
       "305             8.1       13.0     0.278     4.0  reviewed              us   \n",
       "315             7.5        3.7     0.040    60.0  reviewed              us   \n",
       "325             9.9        9.1     0.235     5.0  reviewed              us   \n",
       "333             5.2        2.0     0.049    40.0  reviewed              us   \n",
       "\n",
       "    magSource  \n",
       "6          us  \n",
       "19         us  \n",
       "33         us  \n",
       "49         ak  \n",
       "61         us  \n",
       "80         us  \n",
       "90        guc  \n",
       "93         us  \n",
       "96         us  \n",
       "98         us  \n",
       "115        us  \n",
       "132        us  \n",
       "192        us  \n",
       "200        us  \n",
       "226       guc  \n",
       "289        us  \n",
       "305        us  \n",
       "315        us  \n",
       "325        us  \n",
       "333        us  \n",
       "\n",
       "[20 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete question 2b answer cell\n",
    "def powerful_quakes(mag):\n",
    "    ## This is just returning an empty DataFrame you need to code it to return\n",
    "    ## a DataFrame with all quakes of magnitude greater than or equal to mag\n",
    "    if mag == None:\n",
    "        return pandas.DataFrame()\n",
    "    \n",
    "    powerful_quakes = QUAKE_DF[QUAKE_DF[\"mag\"] >= mag ]\n",
    "    return powerful_quakes\n",
    "\n",
    "powerful_quakes(4.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2c: Find `n+` most powerful earthquakes\n",
    "\n",
    "Produce a DataFrame of the `n`(or maybe more) most powerful quakes. The ``DataFrame`` should show at least `n`\n",
    "quakes and may sometimes show more since we do not want to leave out any quake that is equally\n",
    "powerful as the last quake listed in the `DataFrame`.\n",
    "More specificially, we want the function to return a `DataFrame` that:\n",
    "* lists quakes in descending order of magnitude \n",
    "* contains all and only those quakes in `QUAKES_DF`, such that there are fewer than `n` other quakes in\n",
    "  `QUAKES_DF` that have a higher magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2020-11-15T22:37:43.739Z</td>\n",
       "      <td>8.7425</td>\n",
       "      <td>126.2805</td>\n",
       "      <td>44.51</td>\n",
       "      <td>6.0</td>\n",
       "      <td>mww</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.801</td>\n",
       "      <td>1.02</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T17:06:40.040Z</td>\n",
       "      <td>7 km SSW of Marihatag, Philippines</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.040</td>\n",
       "      <td>60.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2020-11-16T13:42:16.901Z</td>\n",
       "      <td>-10.9304</td>\n",
       "      <td>164.4230</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5.1</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.648</td>\n",
       "      <td>0.61</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T14:33:58.040Z</td>\n",
       "      <td>151 km W of Lata, Solomon Islands</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.058</td>\n",
       "      <td>97.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2020-11-16T15:08:13.140Z</td>\n",
       "      <td>27.6372</td>\n",
       "      <td>129.9391</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.684</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T17:14:03.171Z</td>\n",
       "      <td>92 km SSE of Naze, Japan</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.051</td>\n",
       "      <td>124.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-11-16T20:18:34.076Z</td>\n",
       "      <td>-28.4228</td>\n",
       "      <td>-71.0898</td>\n",
       "      <td>44.10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.70</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-16T20:56:10.040Z</td>\n",
       "      <td>36 km WNW of Vallenar, Chile</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.039</td>\n",
       "      <td>207.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time  latitude  longitude  depth  mag magType  nst  \\\n",
       "315  2020-11-15T22:37:43.739Z    8.7425   126.2805  44.51  6.0     mww  NaN   \n",
       "98   2020-11-16T13:42:16.901Z  -10.9304   164.4230  10.00  5.1      mb  NaN   \n",
       "80   2020-11-16T15:08:13.140Z   27.6372   129.9391  10.00  5.0      mb  NaN   \n",
       "6    2020-11-16T20:18:34.076Z  -28.4228   -71.0898  44.10  5.0      mb  NaN   \n",
       "\n",
       "       gap   dmin   rms  ...                   updated  \\\n",
       "315   33.0  1.801  1.02  ...  2020-11-16T17:06:40.040Z   \n",
       "98    85.0  4.648  0.61  ...  2020-11-16T14:33:58.040Z   \n",
       "80    82.0  1.684  0.80  ...  2020-11-16T17:14:03.171Z   \n",
       "6    115.0  0.217  0.70  ...  2020-11-16T20:56:10.040Z   \n",
       "\n",
       "                                  place        type horizontalError  \\\n",
       "315  7 km SSW of Marihatag, Philippines  earthquake             7.5   \n",
       "98    151 km W of Lata, Solomon Islands  earthquake            10.2   \n",
       "80             92 km SSE of Naze, Japan  earthquake             5.9   \n",
       "6          36 km WNW of Vallenar, Chile  earthquake             4.6   \n",
       "\n",
       "    depthError  magError  magNst    status  locationSource magSource  \n",
       "315        3.7     0.040    60.0  reviewed              us        us  \n",
       "98         1.8     0.058    97.0  reviewed              us        us  \n",
       "80         1.9     0.051   124.0  reviewed              us        us  \n",
       "6          3.2     0.039   207.0  reviewed              us        us  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 2c answer cell\n",
    "def most_powerful_n_quakes(n):\n",
    "    # Edit this function to make it return a DataFrame of the 'top n' quakes of the all_day.csv file\n",
    "    if n == None or n < 1:\n",
    "        return pandas.DataFrame()  \n",
    "    \n",
    "    df = QUAKE_DF.sort_values(by='mag', ascending=False) \n",
    "    mags = sorted(list(set(df['mag'])),reverse=True)\n",
    "    tdf = pandas.DataFrame()\n",
    "    top_n = 0\n",
    "    for mag in mags:\n",
    "        tdf = df[df['mag'] == mag]\n",
    "        top_n += len(tdf)\n",
    "        if top_n >= n:\n",
    "            return df[df['mag'] >= mag]\n",
    "\n",
    "most_powerful_n_quakes(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2d: Identifying Endangered Cities\n",
    "\n",
    "The general idea of this question is to identify possible emergency situations by finding\n",
    "cities over a given population that are within a certain distance of an earthquake of a given\n",
    "magnitude or higher. (The precise specification is after the next code cell.)\n",
    "\n",
    "To help answer this question you are provided with the function ```haversine_distance```, \n",
    "which will find the distance in metres between two locations, that are specified in terms of\n",
    "latitude and longitude values. When finding distances betwen points on the surface of the\n",
    "Earth We need to use this formula, rather than the simpler Pythagorean distance formula,\n",
    "because the Earth's surface is a sphere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute distance between locations (metres) \n",
    "# Returns the distance in meters, according to the Haversine formula,\n",
    "# between two locations given as (latitude, longitude) coordinate pairs.\n",
    "\n",
    "import math\n",
    "def haversine_distance( loc1 , loc2 ): # add wiki link or something\n",
    "    '''finds the distance (m) between 2 locations, where locations are defined by\n",
    "    longitudes and latitudes'''\n",
    "    lat1, lon1 = loc1\n",
    "    lat2, lon2 = loc2\n",
    "    radius = 6371000  # meters\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = (math.sin(dlat / 2) * math.sin(dlat / 2) +\n",
    "         math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) *\n",
    "         math.sin(dlon / 2) * math.sin(dlon / 2))\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `haversine_distance` function, write a function `engangered_cities` that takes \n",
    "three numerica arguments (`population`, `distance` and `magnitude`) and \n",
    "returns a `list` in alphabetical order of the `ascii` names of all cities listed in \n",
    "the 'WC_DF' such that:\n",
    "* they have a population greater than or equal to the given population \n",
    "* their location is at a distance of less than or equal to the given distance from\n",
    "  an earthquake of magnitude greater than or equal to the given magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bacolod',\n",
       " 'Cagayan de Oro',\n",
       " 'Davao',\n",
       " 'General Santos',\n",
       " 'Manila',\n",
       " 'Quezon City']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2d Answer Code Cell\n",
    "def endangered_cities(population, distance, magnitude):\n",
    "    \n",
    "    list_of_endangered_cities = []\n",
    "    # an earthquake of magnitude greater than or equal to the given magnitude.\n",
    "    df_mag = QUAKE_DF[QUAKE_DF['mag'] >= magnitude][['latitude','longitude']]\n",
    "    \n",
    "    # the cities have a population greater than or equal to the given population\n",
    "    df_population = WC_DF[WC_DF['population'] >= population][['city_ascii','lat','lng','population']]\n",
    "    df_population = df_population.sort_values(by='city_ascii', ascending=True)\n",
    "     \n",
    "    for i in range(0, len(df_mag)):\n",
    "        loc1 = [df_mag.iloc[i]['latitude'],df_mag.iloc[i]['longitude']]\n",
    "        for j in range(0, len(df_population)):\n",
    "            loc2 = [df_population.iloc[j]['lat'],df_population.iloc[j]['lng']]\n",
    "            dis_loc1_to_loc2 = haversine_distance(loc1, loc2)\n",
    "            if dis_loc1_to_loc2 <= distance:\n",
    "                list_of_endangered_cities.append(df_population.iloc[j]['city_ascii'])\n",
    "                      \n",
    "    return list_of_endangered_cities\n",
    "\n",
    "endangered_cities(933240, 1000000, 6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Exercises\n",
    "\n",
    "Having got this far, you may find it interesting and informative to do some more processing\n",
    "of the city and earthquake information.\n",
    "\n",
    "### Constructing a city risk status alert `DataFrame`\n",
    "\n",
    "A government or other organisation may want to monitor a certain list of cities with regard to whether\n",
    "they may be at risk of earthquake damage. To answer this question you should create a function\n",
    "that uses the `endangered_cities` function you have defined above to create such a `DataFrame`.\n",
    "\n",
    "Your function `city_risk_alert` should return a pandas DataFrame that includes the status of ```'ENDANGERED'``` or ```'SAFE'``` for a certain city. The dataframe should also contain the city name, country and status for each city input. You could also extend this to add more columns showing\n",
    "things like the distance and magnitude of the nearest earthquake. And you could perhaps make it\n",
    "so any endangered cities were put at the top of the list.\n",
    "\n",
    "For example:\n",
    "```\n",
    "display( city_risk_alert( ['Rome', 'Milan', 'Pisa'] )\n",
    "```\n",
    "\n",
    "might give the following output:\n",
    "\n",
    " \n",
    "| city  | country|status|\n",
    "|-------|-------|-----|\n",
    "| Pisa  | Italy | ENDANGERED |\n",
    "| Rome  | Italy | SAFE |\n",
    "| Milan | Italy | SAFE |\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation Exercise: display endangered cities on a map\n",
    "\n",
    "The code below creates a Map object using the ```ipyleaflet``` module and uses this to\n",
    "display powerful quakes on the map. If you have coded the `powerful_quakes` function for\n",
    "Question 2b above, the code in the cell below the map should draw the detected powerful\n",
    "quakes onto the map at their correct locations.\n",
    "\n",
    "To install the ```ipyleaflet``` module use ```!pip3 install ipyleaflet```. If the map does not display after installation be sure to restart the kernel, and close and reopen this file. We provide the ```draw_circle_on_map``` function, this add circles to a specified location on the map, where the location is defined by longitudes and latitudes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b44cb1f5c5e4e0e8897d3647a8b116c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[53.8008, -1.5491], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, Circle, Polyline\n",
    "from ipywidgets import Layout\n",
    "\n",
    "LEEDS_LOC  = ( 53.8008,  -1.5491  ) # Here we define the longitude and latitude of Leeds\n",
    "WORLD_MAP = Map(basemap=basemaps.OpenTopoMap, center=LEEDS_LOC, zoom=1.5,\n",
    "                layout=Layout(height=\"500px\")) # Here we create a map object centred on Leeds\n",
    "\n",
    "WORLD_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circle_on_map( a_map, location, radius = 1000, color=\"red\", fill_color=None ):\n",
    "    if not fill_color:\n",
    "        fill_color = color\n",
    "    circle = Circle()\n",
    "    circle.location = location\n",
    "    circle.radius = radius\n",
    "    circle.color = color\n",
    "    circle.fill_color = fill_color\n",
    "    a_map.add_layer(circle)\n",
    "    \n",
    "draw_circle_on_map(WORLD_MAP, LEEDS_LOC, color=\"green\" ) # This will edit your previous map rather than produce a new one\n",
    "\n",
    "def display_powerful_quakes_on_map(mag):\n",
    "    powerful = powerful_quakes(3)\n",
    "    for i, quake in powerful.iterrows():\n",
    "        draw_circle_on_map( WORLD_MAP,\n",
    "                            (quake[\"latitude\"],quake[\"longitude\"]), \n",
    "                            radius= 20000*int(quake[\"mag\"]) )\n",
    "\n",
    "display_powerful_quakes_on_map(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Ideas for Graphical Display\n",
    "It would be nice to also see the endangered cities on the map. For an ambitious exercise you\n",
    "could see if you can draw lines on the map running from from the locations of powerful\n",
    "earthquakes to the cities that are endangered by them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
