{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P4DS: Assignment 2 (Autumn 2020)\n",
    "\n",
    "# Data and Algorithms, Part II\n",
    "\n",
    "\n",
    "## Q3. Write a simple spell-checker (10 marks)\n",
    "\n",
    "To answer this question, you need to write a function ```spell_check_file```, which takes\n",
    "one argument that is the name of a file and prints output similar to that given below, showing all words in the file that may be spelling mistakes. More specifically,\n",
    "for each line where _potential spelling mistakes_ are identified, it should\n",
    "``print`` out the line number followed by a list of the words that have been identified\n",
    "as possibly misspelled.\n",
    "\n",
    "Thus the output should be similar to \n",
    "(but not necessarily in the exact same format as) the following, which I obtained by running\n",
    "my code on the file `spelling.txt`:\n",
    "\n",
    "<pre>\n",
    "    3 : ['primarry', 'secondarry']\n",
    "    4 : ['recieved', 'Phisics']\n",
    "    5 : ['Comunication', 'Religeon', 'll']\n",
    "    8 : ['ambigous']\n",
    "    9 : ['cource']\n",
    "   10 : ['atempt', 'commprehend', 'Luckilly']\n",
    "   12 : ['aquainted', 'langauge']\n",
    "   13 : ['simillar']\n",
    "   14 : ['paticular']\n",
    "   22 : ['expresion']\n",
    "   23 : ['expresive']\n",
    "</pre>\n",
    "\n",
    "### Important note on output form\n",
    "Please not that (unlike Assignment 1 and Part I of Assignment 2)\n",
    "for this quesiton your code should actually display the output\n",
    "using `print` statements. That is because this question\n",
    "will not be marked by an autograder. We \n",
    "shall actually be looking at your code and running it, and it \n",
    "will be easier for us to interpret nicely formatted output than\n",
    "a big datastructure. Also it gives you a little bit of practice\n",
    "in formatting.\n",
    "\n",
    "#### Assumptions:\n",
    "You may assume the following:\n",
    "* The file to be tested is in the same folder as your program       file, and the correct file name is always given as\n",
    "  the argument to `spell_check_file`.\n",
    "* The file `english_words.txt` is also in the same folder.\n",
    "* The input file is in ASCII encoding (or in a UTF-8 encoding\n",
    "  that can be treated as ASCII).*\n",
    "\n",
    "####  \\*Note on encodings: \n",
    "The fact that files can use different character encodings can\n",
    "potentially cause problems for this kind of functionality.\n",
    "Hence, I will only test on ASCII files. Many files are actually\n",
    "formatted using more complex encodings. But many files that\n",
    "are specified as being UTF-8 can be treated as ASCII.\n",
    "In fact ASCII files can, in nearly all cases, be considered \n",
    "to be in UTF-8. (Techinically ASCII is a 7-bit encoding, which\n",
    "means that it has a spare bit that is not used but is\n",
    "used by UTF-8 to extend ASCII to much larger character sets. However, in rare cases software working with ASCII could use the \n",
    "spare 8th bit of an ASCII byte for some special purpose. This\n",
    "would mess up the UTF-8 interpretation of the file. But one\n",
    "could then just set all the spare bits to 0, which would turn\n",
    "it to UTF-8 that is equivalent to the original ASCII).\n",
    "\n",
    "A very good article on character encodings by Stack Exchange co-founder Joel Spolsky [here](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/)\n",
    "\n",
    "The books files in the module [data repository](https://teaching.bb-ai.net/P4DS/data/index.html) are in plain ASCII (apart from the book Antic Hay (which is in UTF-8-SIG). You may also be interested to download addtional book data from [Project Gutenberg](https://www.gutenberg.org/), which is\n",
    "a nice resource for people interested in classic books.\n",
    "The file format used there is actually `UTF-8-SIG`, which is\n",
    "basically just `ASCII` but with a special extra byte (a [BOM](https://en.wikipedia.org/wiki/Byte_order_mark)) at the\n",
    "beginning of the file. This probably will not cause a problem,\n",
    "but, if it does, it is fairly easy to remove this first byte.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Restrictions and Size Limits\n",
    "\n",
    "Your code should be written within this file and the name of the file\n",
    "should not be changed.\n",
    "\n",
    "I am looking for a self-contained, simple and concise piece of code which does a reasonable job of identifying potential spelling mistakes. \n",
    "Hence, Your code should satisfy the following limiations:\n",
    "* It should __not__ `import` any modules.\n",
    "* It should __not__ make use of any functions or constants defined\n",
    "  in other cells.\n",
    "* It should __not__ exceed 50 lines of code but blank lines and lines that\n",
    "  define a function (i.e. start with `def`) are not included. \n",
    "* It should __not__ contain any line longer than 80 characers wide.\n",
    "\n",
    "My solution, that produced the output shown above, falls well within these\n",
    "restrictions, consisting of 16 lines of code. However, my code could \n",
    "certainly be improved with some additional checks.\n",
    "\n",
    "The reason that `def` lines are excluded is that it is nearly always\n",
    "a good idea to break down a complex function into simpler parts. So you\n",
    "will not use up the line limit by doing this. In particular, \n",
    "you will need a function like `get_english_words` to\n",
    "get read the words from the `english_words.txt` file;\n",
    "and it is probably\n",
    "a good idea to have a function that checks words (similar to the\n",
    "`is_english_word` function), which is separtate from\n",
    "the main function that processes the whole file.\n",
    "\n",
    "\n",
    "### Notes and Sugestions\n",
    "\n",
    "I have not specified exactly which strings in the input file should \n",
    "be counted as _\"potential spelling mistakes\"_. This is intentended, since I want\n",
    "you to think of the problem as one of real data handling, rather than a purely\n",
    "artificial exercise. Like many real problems involving manipulation of real data, \n",
    "exact criteria that determine its interpretation and classification may be difficult \n",
    "or even impossible to state precisely. In such cases, we typically start with\n",
    "an intuitive idea of what we want to do with the data, and soon realise that\n",
    "we have to make this more precise to actually implement a solution. We then\n",
    "try to specify the details of the processing required and results we want to\n",
    "obtain. After some analysis and consideration of examples, we can usually\n",
    "come up with a speicification that works well and gives useful\n",
    "results in nearly all cases. However, for a real problem involving \n",
    "a complex real data sorce, it is unlikely that we can find a solution that\n",
    "gives useful and desirable results in 100% of cases.\n",
    "\n",
    "#### Some useful functions to construct a simple solution\n",
    "\n",
    "Clearly, the `is_english_word` function that you defined in the previous \n",
    "assignment, or something similar, will be very useful. \n",
    "You may assume that any English word is not a spelling mistake.\n",
    "\n",
    "The following basic Python built-in functions are very useful for manipulating\n",
    "raw data:\n",
    "* `tokens = s.split()` --- Use this kind of construct to chop a string (or whole\n",
    "   document contents into parts. Given no arguments it will split a string at\n",
    "   all points where there is whitespace (spaces, tabs and/or newlines).\n",
    "* `s = s.strip()`  --- This construct will replace `s` by a cleaned up version\n",
    "   with no whitespace at either end (but can be in the middle).\n",
    "* `s = s.replace(x,y)` --- replace all occurrences of `x` with `y` in the string \n",
    "    `s`, where `x` and `y` can be either single characters or strings.\n",
    "* `s = s.replace(x,'')` --- replace all occurrences of `x` in `s` by nothing \n",
    "   --- i.e. delete them.\n",
    "\n",
    "#### Issues to deal with\n",
    "\n",
    "* Punctuation --- this presents an immediate problem, especially since punctuation\n",
    "  symbols may occur directly before or after a word. Worse still, certain punctuation\n",
    "  marks such as hypens and apostrophes may occur within a word. Many cases can be\n",
    "  dealt with by simply deleting punctuation symbols, but this is by no means a perfect\n",
    "  solution. \n",
    "  \n",
    "* Odd capitalisation --- our `is_english_word` function assumes that an English word must be either: all lower case, all uppoer case, or, start with an upper case letter and have\n",
    "the rest all lower. This is quite a good rule but different forms are sometimes used\n",
    "(for example `eBook`).\n",
    "\n",
    "* Unusual or colloquial words --- clearly many books contain\n",
    "  peculiar non-standard words, especially in quoted speech.\n",
    "\n",
    "* Proper names. Typically, these start with a capital letter; but how can you tell\n",
    "  a proper name from a wrongly spelled word that is capitalised because it is at the\n",
    "  beginning of a sentence? There is no easy way. \n",
    "\n",
    "* Runtime --- checking words against a list of corret English words can take a long\n",
    "  time if every word is being checked against every word in the list. However,\n",
    "  most of this time is unnecessary. Preprocessing of a list can enable one to tell\n",
    "  much more quickly whether it contains a given element. \n",
    "  \n",
    "I do not expect your code to perfectly solve any of these problems, but try to deal\n",
    "with them as best you can given the code length restrictions given above and the\n",
    "limited time you have available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marks Guidline\n",
    "The 10 marks are assigned according to the overall quality\n",
    "of your solution. They will normally be allocated according to the following proportions:\n",
    "\n",
    "* Basic functionality and output format (4 marks)\n",
    "* Accuracy in identifiying incorrect words (compared to\n",
    "  reasonable expectations) (5)\n",
    "* Speed performance on a large text (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please put all your code of your answer in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q3 answer code cell\n",
    "## Modify this function definition to fulfill the given requirements.\n",
    "## Maximum code length: 50 lines\n",
    "\n",
    "# Get all English words set.\n",
    "def get_english_words():\n",
    "    with open(\"english_words.txt\") as f:\n",
    "        words = f.readlines()\n",
    "    return {word.strip() for word in words}\n",
    "\n",
    "# all words set\n",
    "ENGLISH_WORDS = get_english_words()\n",
    "\n",
    "# Determine if a word is an english word.\n",
    "def is_english_word(s):\n",
    "    return True if (s.islower() or s.istitle() or s.isupper()) and s.lower() in ENGLISH_WORDS else False\n",
    "\n",
    "# Get numbers of every word appears in text.\n",
    "def get_word_counts(words):\n",
    "    dicts = {}\n",
    "    for key in words:\n",
    "        dicts[key] = dicts.get(key, 0) + 1\n",
    "    dicts = sorted(dicts.items(), key=lambda x: x[1], reverse=True)  \n",
    "    return dicts\n",
    "\n",
    "# Compute the credibility score of each word\n",
    "def compute_word_reliability(word_count, n=10):\n",
    "    \"\"\"\n",
    "    The algorithm logic as following: (The algorithm can deal with large text well.)\n",
    "    1, If a word is in the set of 'ENGLISH_WORDS', then credibility score of the word is 100.\n",
    "    2, If a word appears in the text more than 20 times, which would be reasonable to believe \n",
    "    that it is a right word and credibility score of the word is 100, \n",
    "    becasue the probability(about 1/2^20) of a word being wrong 20 times in a text is very low.\n",
    "    3, If a word appears in the text more than 'n' and less than 20, the credibility score of the word\n",
    "    range in [50, 100)\n",
    "    4, If a word appears in the text less than 'n', and the credibility score of the word range in (0, 50)\n",
    "    \"\"\"\n",
    "    word_reliability = {}\n",
    "    for k, v in word_count.items():\n",
    "        if k != '' and is_english_word(k): w = {k: 100}\n",
    "        elif v >= 20: w = {k: 100}   \n",
    "        elif n <= v < 20: w = {k: 50 + (v - n) * 5}\n",
    "        else: w = {k: v * 5}\n",
    "            \n",
    "        word_reliability.update(w)\n",
    "        \n",
    "    return word_reliability\n",
    "\n",
    "\n",
    "# Spelling mistakes check function\n",
    "def spell_check_file(filename):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "    1, open the source text.\n",
    "    2, loop every line of the text, then remove the special punctuation in every line.\n",
    "    3, every line convert into list, then remove the special char of every word.\n",
    "    4, count numbers of every word appears in text.\n",
    "    5, compute the credibility score of each word.\n",
    "    \"\"\"  \n",
    "    # specil_chars appears in text\n",
    "    line_special_chars = ['|','+',';', '!', '?', '_', '(', ')', '\"', '*', '[', ']', '{', '}', '&', \n",
    "                          '#','=','>','$','%','-','”','-','...',\".'\",'.\"','.”','—']\n",
    "    # specil_words appears in text\n",
    "    special_words = [\"'s\", \"’s\",\"’S\", \"'d\", \"'t\", \"'ll\", \"'ve\", \"'re\", \"www.\", \"http:\", \".org\"]\n",
    "    # including unusual or colloquial words, common words, proper names, country or place names, specil number etc. \n",
    "    common_words  = [\"EBook\", \"eBook\", \"ebook\", \"MR\",\"Mrs\",\"Dr\"]\n",
    "    words_count = {}\n",
    "    list_lines = []\n",
    "    # step1, open the source text\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        # step2, remove the special punctuation in every line.\n",
    "        for char in line_special_chars:\n",
    "            line = line.strip().replace(char,' ')\n",
    "            \n",
    "        # step3, remove the special char of every word. \n",
    "        list_line = (' '.join(line.split())).split(' ')\n",
    "        for i in range(len(list_line)):\n",
    "            if list_line[i].endswith(':') or list_line[i].endswith('.') or list_line[i].endswith(',') or list_line[i].endswith(\"'\"):\n",
    "                list_line[i] = list_line[i][:-1]\n",
    "            if list_line[i].startswith(\"'\"):\n",
    "                list_line[i] = list_line[i][1:]\n",
    "        \n",
    "        # step4, count numbers of every word appears in text.\n",
    "        for k, v in get_word_counts(list_line):\n",
    "            temp = {k: words_count.get(k) + v} if k in words_count else {k: v}\n",
    "            words_count.update(temp)\n",
    "\n",
    "        list_lines.append(list_line)\n",
    "\n",
    "    # step5, compute the credibility score of each word.\n",
    "    words_reliability = compute_word_reliability(words_count, 10)\n",
    "    print('Line number : [{word, score of reliability}, ...]')\n",
    "    for j in range(len(list_lines)):\n",
    "        list_line = list_lines[j]      \n",
    "        for sw in special_words:\n",
    "            list_line = [ls for ls in list_line if not ls.endswith(sw) and not ls.isnumeric() and sw not in ls]\n",
    "        \n",
    "        for cw in common_words:\n",
    "            list_line = [ls for ls in list_line if cw != ls and cw.upper() != ls and cw.title() != ls]\n",
    "            \n",
    "        mistake_words = [{lw: words_reliability.get(lw)} for lw in list_line if len(lw) > 1 and words_reliability.get(lw) < 50]\n",
    "    \n",
    "        if len(mistake_words) > 0: print(j, ':', mistake_words)\n",
    "            \n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spell_check_file` testing\n",
    "Run the following cell to run your `spell_check_file` function on the\n",
    "example file `spelling.txt` and see the result.\n",
    "\n",
    "* Download [`spelling.txt`](https://teaching.bb-ai.net/P4DS/data/spelling.txt)\n",
    "\n",
    "You may want to also test your `spell_check_file` function with some other\n",
    "longer examples. But please\n",
    "delete such tests from the final version you submit, since your\n",
    "code will give an error if it tries to load an external file.\n",
    "\n",
    "Please leave the ``%%time`` instruction, which causes Jupyter\n",
    "to measure and display the execution time of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line number : [{word, score of reliability}, ...]\n",
      "3 : [{'primarry': 5}, {'secondarry': 5}]\n",
      "4 : [{'recieved': 5}, {'Phisics': 5}]\n",
      "5 : [{'Comunication': 5}, {'Religeon': 5}]\n",
      "8 : [{'ambigous': 5}]\n",
      "9 : [{'cource': 5}]\n",
      "10 : [{'atempt': 5}, {'commprehend': 5}, {'Luckilly': 5}]\n",
      "12 : [{'aquainted': 5}, {'langauge': 5}]\n",
      "13 : [{'simillar': 5}]\n",
      "14 : [{'paticular': 5}]\n",
      "22 : [{'expresion': 5}]\n",
      "23 : [{'expresive': 5}]\n",
      "CPU times: user 4.01 ms, sys: 936 µs, total: 4.94 ms\n",
      "Wall time: 4.27 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spell_check_file(\"spelling.txt\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "_Please leave this cell. The marker will write feedback here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please leave this cell.\n",
    "# The marker will fill in your grade here.\n",
    "Q3_GRADE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
