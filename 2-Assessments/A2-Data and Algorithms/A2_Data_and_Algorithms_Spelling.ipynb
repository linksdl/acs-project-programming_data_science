{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P4DS: Assignment 2 (Autumn 2020)\n",
    "\n",
    "# Data and Algorithms, Part II\n",
    "\n",
    "\n",
    "## Q3. Write a simple spell-checker (10 marks)\n",
    "\n",
    "To answer this question, you need to write a function ```spell_check_file```, which takes\n",
    "one argument that is the name of a file and prints output similar to that given below, showing all words in the file that may be spelling mistakes. More specifically,\n",
    "for each line where _potential spelling mistakes_ are identified, it should\n",
    "``print`` out the line number followed by a list of the words that have been identified\n",
    "as possibly misspelled.\n",
    "\n",
    "Thus the output should be similar to \n",
    "(but not necessarily in the exact same format as) the following, which I obtained by running\n",
    "my code on the file `spelling.txt`:\n",
    "\n",
    "<pre>\n",
    "    3 : ['primarry', 'secondarry']\n",
    "    4 : ['recieved', 'Phisics']\n",
    "    5 : ['Comunication', 'Religeon', 'll']\n",
    "    8 : ['ambigous']\n",
    "    9 : ['cource']\n",
    "   10 : ['atempt', 'commprehend', 'Luckilly']\n",
    "   12 : ['aquainted', 'langauge']\n",
    "   13 : ['simillar']\n",
    "   14 : ['paticular']\n",
    "   22 : ['expresion']\n",
    "   23 : ['expresive']\n",
    "</pre>\n",
    "\n",
    "### Important note on output form\n",
    "Please not that (unlike Assignment 1 and Part I of Assignment 2)\n",
    "for this quesiton your code should actually display the output\n",
    "using `print` statements. That is because this question\n",
    "will not be marked by an autograder. We \n",
    "shall actually be looking at your code and running it, and it \n",
    "will be easier for us to interpret nicely formatted output than\n",
    "a big datastructure. Also it gives you a little bit of practice\n",
    "in formatting.\n",
    "\n",
    "#### Assumptions:\n",
    "You may assume the following:\n",
    "* The file to be tested is in the same folder as your program       file, and the correct file name is always given as\n",
    "  the argument to `spell_check_file`.\n",
    "* The file `english_words.txt` is also in the same folder.\n",
    "* The input file is in ASCII encoding (or in a UTF-8 encoding\n",
    "  that can be treated as ASCII).*\n",
    "\n",
    "####  \\*Note on encodings: \n",
    "The fact that files can use different character encodings can\n",
    "potentially cause problems for this kind of functionality.\n",
    "Hence, I will only test on ASCII files. Many files are actually\n",
    "formatted using more complex encodings. But many files that\n",
    "are specified as being UTF-8 can be treated as ASCII.\n",
    "In fact ASCII files can, in nearly all cases, be considered \n",
    "to be in UTF-8. (Techinically ASCII is a 7-bit encoding, which\n",
    "means that it has a spare bit that is not used but is\n",
    "used by UTF-8 to extend ASCII to much larger character sets. However, in rare cases software working with ASCII could use the \n",
    "spare 8th bit of an ASCII byte for some special purpose. This\n",
    "would mess up the UTF-8 interpretation of the file. But one\n",
    "could then just set all the spare bits to 0, which would turn\n",
    "it to UTF-8 that is equivalent to the original ASCII).\n",
    "\n",
    "A very good article on character encodings by Stack Exchange co-founder Joel Spolsky [here](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/)\n",
    "\n",
    "The books files in the module [data repository](https://teaching.bb-ai.net/P4DS/data/index.html) are in plain ASCII (apart from the book Antic Hay (which is in UTF-8-SIG). You may also be interested to download addtional book data from [Project Gutenberg](https://www.gutenberg.org/), which is\n",
    "a nice resource for people interested in classic books.\n",
    "The file format used there is actually `UTF-8-SIG`, which is\n",
    "basically just `ASCII` but with a special extra byte (a [BOM](https://en.wikipedia.org/wiki/Byte_order_mark)) at the\n",
    "beginning of the file. This probably will not cause a problem,\n",
    "but, if it does, it is fairly easy to remove this first byte.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Restrictions and Size Limits\n",
    "\n",
    "Your code should be written within this file and the name of the file\n",
    "should not be changed.\n",
    "\n",
    "I am looking for a self-contained, simple and concise piece of code which does a reasonable job of identifying potential spelling mistakes. \n",
    "Hence, Your code should satisfy the following limiations:\n",
    "* It should __not__ `import` any modules.\n",
    "* It should __not__ make use of any functions or constants defined\n",
    "  in other cells.\n",
    "* It should __not__ exceed 50 lines of code but blank lines and lines that\n",
    "  define a function (i.e. start with `def`) are not included. \n",
    "* It should __not__ contain any line longer than 80 characers wide.\n",
    "\n",
    "My solution, that produced the output shown above, falls well within these\n",
    "restrictions, consisting of 16 lines of code. However, my code could \n",
    "certainly be improved with some additional checks.\n",
    "\n",
    "The reason that `def` lines are excluded is that it is nearly always\n",
    "a good idea to break down a complex function into simpler parts. So you\n",
    "will not use up the line limit by doing this. In particular, \n",
    "you will need a function like `get_english_words` to\n",
    "get read the words from the `english_words.txt` file;\n",
    "and it is probably\n",
    "a good idea to have a function that checks words (similar to the\n",
    "`is_english_word` function), which is separtate from\n",
    "the main function that processes the whole file.\n",
    "\n",
    "\n",
    "### Notes and Sugestions\n",
    "\n",
    "I have not specified exactly which strings in the input file should \n",
    "be counted as _\"potential spelling mistakes\"_. This is intentended, since I want\n",
    "you to think of the problem as one of real data handling, rather than a purely\n",
    "artificial exercise. Like many real problems involving manipulation of real data, \n",
    "exact criteria that determine its interpretation and classification may be difficult \n",
    "or even impossible to state precisely. In such cases, we typically start with\n",
    "an intuitive idea of what we want to do with the data, and soon realise that\n",
    "we have to make this more precise to actually implement a solution. We then\n",
    "try to specify the details of the processing required and results we want to\n",
    "obtain. After some analysis and consideration of examples, we can usually\n",
    "come up with a speicification that works well and gives useful\n",
    "results in nearly all cases. However, for a real problem involving \n",
    "a complex real data sorce, it is unlikely that we can find a solution that\n",
    "gives useful and desirable results in 100% of cases.\n",
    "\n",
    "#### Some useful functions to construct a simple solution\n",
    "\n",
    "Clearly, the `is_english_word` function that you defined in the previous \n",
    "assignment, or something similar, will be very useful. \n",
    "You may assume that any English word is not a spelling mistake.\n",
    "\n",
    "The following basic Python built-in functions are very useful for manipulating\n",
    "raw data:\n",
    "* `tokens = s.split()` --- Use this kind of construct to chop a string (or whole\n",
    "   document contents into parts. Given no arguments it will split a string at\n",
    "   all points where there is whitespace (spaces, tabs and/or newlines).\n",
    "* `s = s.strip()`  --- This construct will replace `s` by a cleaned up version\n",
    "   with no whitespace at either end (but can be in the middle).\n",
    "* `s = s.replace(x,y)` --- replace all occurrences of `x` with `y` in the string \n",
    "    `s`, where `x` and `y` can be either single characters or strings.\n",
    "* `s = s.replace(x,'')` --- replace all occurrences of `x` in `s` by nothing \n",
    "   --- i.e. delete them.\n",
    "\n",
    "#### Issues to deal with\n",
    "\n",
    "* Punctuation --- this presents an immediate problem, especially since punctuation\n",
    "  symbols may occur directly before or after a word. Worse still, certain punctuation\n",
    "  marks such as hypens and apostrophes may occur within a word. Many cases can be\n",
    "  dealt with by simply deleting punctuation symbols, but this is by no means a perfect\n",
    "  solution. \n",
    "  \n",
    "* Odd capitalisation --- our `is_english_word` function assumes that an English word must be either: all lower case, all uppoer case, or, start with an upper case letter and have\n",
    "the rest all lower. This is quite a good rule but different forms are sometimes used\n",
    "(for example `eBook`).\n",
    "\n",
    "* Unusual or colloquial words --- clearly many books contain\n",
    "  peculiar non-standard words, especially in quoted speech.\n",
    "\n",
    "* Proper names. Typically, these start with a capital letter; but how can you tell\n",
    "  a proper name from a wrongly spelled word that is capitalised because it is at the\n",
    "  beginning of a sentence? There is no easy way. \n",
    "\n",
    "* Runtime --- checking words against a list of corret English words can take a long\n",
    "  time if every word is being checked against every word in the list. However,\n",
    "  most of this time is unnecessary. Preprocessing of a list can enable one to tell\n",
    "  much more quickly whether it contains a given element. \n",
    "  \n",
    "I do not expect your code to perfectly solve any of these problems, but try to deal\n",
    "with them as best you can given the code length restrictions given above and the\n",
    "limited time you have available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marks Guidline\n",
    "The 10 marks are assigned according to the overall quality\n",
    "of your solution. They will normally be allocated according to the following proportions:\n",
    "\n",
    "* Basic functionality and output format (4 marks)\n",
    "* Accuracy in identifiying incorrect words (compared to\n",
    "  reasonable expectations) (5)\n",
    "* Speed performance on a large text (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please put all your code of your answer in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 answer code cell\n",
    "# Modify this function definition to fulfill the given requirements.\n",
    "# Maximum code length: 50 lines\n",
    "\n",
    "# Get all English words set.\n",
    "def get_english_words():\n",
    "    with open(\"english_words.txt\") as f:\n",
    "        words = f.readlines()\n",
    "    words = {word.strip() for\n",
    "             word in words}\n",
    "    return words\n",
    "\n",
    "# all words set\n",
    "ENGLISH_WORDS = get_english_words()\n",
    "\n",
    "# Determine if a word is an english word.\n",
    "def is_english_word(s):\n",
    "    return True if (s.islower() or s.istitle() or s.isupper()) and s.lower() in ENGLISH_WORDS else False\n",
    "\n",
    "def count_words(words):\n",
    "    dicts = {}\n",
    "    for key in words:\n",
    "        dicts[key] = dicts.get(key, 0) + 1\n",
    "    dicts = sorted(dicts.items(), key=lambda x: x[1], reverse=True)  \n",
    "    return dicts\n",
    "\n",
    "# compute reliability of every word\n",
    "def compute_word_reliability(n, word_count):\n",
    "    # 1. If the word is in english_words, then the reliability is 100\n",
    "    # 2. If the number of word occur in text more than n and less than 16, the reliability range in [50, 90)\n",
    "    # 3. if the number of word occur in text more than 16, the reliability >= 90\n",
    "    word_reliability = {}\n",
    "    for k, v in word_count.items():\n",
    "        if k != '' and is_english_word(k):\n",
    "            w = {k: 100}\n",
    "        elif v >= 16:\n",
    "            w = {k: 90 + (v - 15) * 1}\n",
    "        elif n <= v < 16:\n",
    "            w = {k: 50 + (v - n) * 3}\n",
    "        else:\n",
    "            w = {k: v * 10}\n",
    "        word_reliability.update(w)\n",
    "\n",
    "    return word_reliability\n",
    "\n",
    "# spell checking function\n",
    "def spell_check_file(filename):\n",
    "    # Open the source text\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    special_char = ',;!?_()\"*[]{}&#=>'\n",
    "    words_count = {}\n",
    "    list_lines = []\n",
    "    number_for_reliable = 3\n",
    "    score_for_reliable = 55\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        # step1, remove the special char in the text\n",
    "        for char in special_char:\n",
    "            line = line.strip().replace(char, ' ').replace('--', ' ').replace('...', ' ').replace(\".'\", ' ')\n",
    "        list_line = (' '.join(line.split())).split(' ')\n",
    "\n",
    "        # step2, remove the special char in the word\n",
    "        for j in range(len(list_line)):\n",
    "            if len(list_line[j]) > 0 and (\n",
    "                    list_line[j][-1] == '.' or list_line[j][-1] == ':' or list_line[j][-1] == \"'\"):\n",
    "                list_line[j] = list_line[j][:-1]\n",
    "\n",
    "            if len(list_line[j]) > 0 and (list_line[j][0] == \"'\"):\n",
    "                list_line[j] = list_line[j][1:]\n",
    "\n",
    "        for k, v in count_words(list_line):\n",
    "            temp = {k: words_count.get(k) + v} if k in words_count else {k: v}\n",
    "            words_count.update(temp)\n",
    "\n",
    "        list_lines.append(list_line)\n",
    "\n",
    "    # compute the every word reliability.\n",
    "    words_reliability = compute_word_reliability(number_for_reliable, words_count)\n",
    "\n",
    "    for j in range(len(list_lines)):\n",
    "        list_line = list_lines[j]\n",
    "        spcial_words = [\"'s\", \"'d\", \"'t\", \"'ll\", \"'ve\", \"-\", \"www.\", \"http:\", \".org\"]\n",
    "        # step3, remove the special words and digit base on the special words list\n",
    "        for k in range(len(spcial_words)):\n",
    "            w = spcial_words[k]\n",
    "            list_line = [ls for ls in list_line if not w in ls and not ls.isdigit()]\n",
    "            \n",
    "        error_words = []\n",
    "        for lw in list_line:\n",
    "            if len(lw) > 1 and words_reliability.get(lw) < score_for_reliable:\n",
    "                d = {lw: words_reliability.get(lw)}\n",
    "                error_words.append(d)\n",
    "\n",
    "        if len(error_words) > 0:\n",
    "            print(j, ':', error_words)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spell_check_file` testing\n",
    "Run the following cell to run your `spell_check_file` function on the\n",
    "example file `spelling.txt` and see the result.\n",
    "\n",
    "* Download [`spelling.txt`](https://teaching.bb-ai.net/P4DS/data/spelling.txt)\n",
    "\n",
    "You may want to also test your `spell_check_file` function with some other\n",
    "longer examples. But please\n",
    "delete such tests from the final version you submit, since your\n",
    "code will give an error if it tries to load an external file.\n",
    "\n",
    "Please leave the ``%%time`` instruction, which causes Jupyter\n",
    "to measure and display the execution time of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [{'Ernest': 20}, {'Vincent': 20}]\n",
      "17 : [{'Ernest': 20}, {'Vincent': 20}]\n",
      "21 : [{'November': 10}]\n",
      "28 : [{'GUTENBERG': 50}, {'GADSBY': 53}]\n",
      "31 : [{'Stephen': 10}, {'Hutcheson': 10}]\n",
      "36 : [{'GADSBY': 53}]\n",
      "45 : [{'ERNEST': 20}, {'VINCENT': 20}]\n",
      "53 : [{'Wetzel': 20}, {'Co': 20}, {'Inc': 20}]\n",
      "54 : [{'Los': 20}, {'Angeles': 20}, {'California': 50}]\n",
      "58 : [{'Wetzel': 20}, {'Co': 20}, {'Inc': 20}]\n",
      "68 : [{'ERNEST': 20}, {'VINCENT': 20}]\n",
      "101 : [{'Mr': 10}]\n",
      "102 : [{'Mrs': 10}]\n",
      "134 : [{'etc': 20}]\n",
      "143 : [{'York': 10}]\n",
      "166 : [{'etc': 20}]\n",
      "174 : [{'Los': 20}, {'Angeles': 20}, {'California': 50}]\n",
      "175 : [{'February': 10}]\n",
      "195 : [{'quo': 20}]\n",
      "253 : [{'Asia': 10}, {'Yucatan': 10}, {'Africa': 10}, {'Italy': 50}]\n",
      "255 : [{'Ankhor': 10}, {'Damascus': 10}, {'Baghdad': 10}, {'Samarkand': 10}]\n",
      "285 : [{'Spaniard': 20}]\n",
      "401 : [{'Zulus': 20}]\n",
      "490 : [{'phwat': 50}, {'Worra': 20}, {'worra': 53}]\n",
      "491 : [{'sich': 50}, {'opporchunity': 10}]\n",
      "492 : [{'boozin': 10}, {'tobacca': 10}, {'shmokin': 10}]\n",
      "533 : [{'Washington': 53}]\n",
      "550 : [{'cityish': 10}]\n",
      "568 : [{'Italian': 50}]\n",
      "571 : [{'thinka': 10}, {'worka': 10}, {'firsta': 10}]\n",
      "572 : [{'talka': 10}, {'laugha': 10}, {'tinkin': 10}, {'startin': 10}]\n",
      "573 : [{'patcha': 10}, {'boota': 10}, {'lasta': 10}, {'Thisa': 10}]\n",
      "574 : [{'righta': 10}, {'mucha': 10}]\n",
      "593 : [{'Spaniard': 20}]\n",
      "594 : [{'Russian': 10}, {'Italy': 50}, {'Norway': 10}]\n",
      "600 : [{'II': 10}]\n",
      "656 : [{'curvingly': 10}]\n",
      "796 : [{'III': 10}]\n",
      "823 : [{'townsfolks': 20}]\n",
      "855 : [{'Indians': 10}]\n",
      "901 : [{'townsfolks': 20}]\n",
      "904 : [{'GADSBY': 53}]\n",
      "999 : [{'IV': 10}]\n",
      "1051 : [{'Dorothy': 10}]\n",
      "1052 : [{'Fitts': 10}]\n",
      "1053 : [{'Worthington': 10}]\n",
      "1054 : [{'Hamilton': 10}]\n",
      "1055 : [{'Oscar': 10}, {'Knott': 10}]\n",
      "1056 : [{'Sundays': 20}]\n",
      "1118 : [{'Saturn': 10}]\n",
      "1227 : [{'Faust': 20}]\n",
      "1228 : [{'Aida': 10}, {'Martha': 10}]\n",
      "1229 : [{'Sousa': 10}, {'Strauss': 10}]\n",
      "1263 : [{'calladium': 10}]\n",
      "1289 : [{'Washington': 53}]\n",
      "1299 : [{'Florida': 10}]\n",
      "1317 : [{'VI': 10}]\n",
      "1348 : [{\"Zoo'\": 10}]\n",
      "1370 : [{'phwat': 50}]\n",
      "1371 : [{'sich': 50}, {'woild': 10}]\n",
      "1372 : [{'worra': 53}, {'worra': 53}, {'dinin': 10}]\n",
      "1373 : [{'Wid': 20}]\n",
      "1375 : [{'whoopin': 10}, {'phwat': 50}, {'widout': 10}, {'goin': 10}]\n",
      "1384 : [{'roight': 50}, {'roight': 50}, {'roight': 50}]\n",
      "1389 : [{'darlin': 20}]\n",
      "1418 : [{'Olympic': 10}]\n",
      "1451 : [{'VII': 10}]\n",
      "1456 : [{'orthographically': 10}]\n",
      "1470 : [{'African': 10}]\n",
      "1490 : [{'Ryan': 53}]\n",
      "1501 : [{'Worra': 20}, {'worra': 53}]\n",
      "1502 : [{'Australia': 20}]\n",
      "1519 : [{'Australian': 20}]\n",
      "1618 : [{'VIII': 10}]\n",
      "1665 : [{'Santa': 20}, {'Claus': 20}]\n",
      "1682 : [{'Thompson': 20}]\n",
      "1741 : [{'IX': 10}]\n",
      "1842 : [{'Canada': 10}, {'Russia': 10}, {'Spain': 20}, {'Australia': 20}]\n",
      "1862 : [{'wiltingly': 10}]\n",
      "1905 : [{'Faust': 20}]\n",
      "1953 : [{'aggravatingly': 10}]\n",
      "2041 : [{'Cora': 10}]\n",
      "2069 : [{'doorwards': 10}]\n",
      "2075 : [{'shhhh': 10}]\n",
      "2078 : [{'Ryan': 53}]\n",
      "2086 : [{'XII': 10}]\n",
      "2116 : [{'Washington': 53}]\n",
      "2118 : [{'inconspicuosity': 10}]\n",
      "2123 : [{'San': 10}, {'Francisco': 10}, {'Honolulu': 10}]\n",
      "2124 : [{'Kong': 10}, {'Colombo': 10}, {'Cairo': 50}, {'Cairo': 50}]\n",
      "2130 : [{'Cairo': 50}, {'Italy': 50}]\n",
      "2131 : [{'Spain': 20}, {'London': 10}, {'Atlantic': 53}]\n",
      "2141 : [{'Atlantic': 53}]\n",
      "2182 : [{'XIII': 10}]\n",
      "2324 : [{'Chicago': 10}]\n",
      "2325 : [{'California': 50}]\n",
      "2329 : [{'Ooooo': 10}, {'Missouri': 20}, {'Mississippi': 20}]\n",
      "2333 : [{'Missouri': 20}]\n",
      "2419 : [{'dunno': 50}]\n",
      "2451 : [{'XIV': 10}]\n",
      "2475 : [{'Judy': 10}]\n",
      "2547 : [{'hospitalwards': 10}]\n",
      "2559 : [{'Zulu': 50}]\n",
      "2588 : [{'XV': 10}]\n",
      "2678 : [{'murmurings': 10}]\n",
      "2752 : [{'Allison': 50}]\n",
      "2761 : [{'Allison': 50}]\n",
      "2762 : [{'snappingly': 10}]\n",
      "2767 : [{'Allison': 50}]\n",
      "2784 : [{'XVI': 10}]\n",
      "2814 : [{'nothin': 20}, {'lovin': 10}, {'Wid': 20}]\n",
      "2816 : [{'dunno': 50}, {'havin': 10}]\n",
      "2830 : [{'Jap': 10}]\n",
      "2914 : [{'XVII': 10}]\n",
      "3071 : [{'XVIII': 10}]\n",
      "3087 : [{'babyship': 10}]\n",
      "3143 : [{'schoolday': 10}]\n",
      "3170 : [{'ballbats': 10}]\n",
      "3184 : [{'brasswork': 10}]\n",
      "3227 : [{'Italian': 50}, {'Mio': 10}]\n",
      "3233 : [{'Spanish': 10}]\n",
      "3237 : [{'Zulus': 20}]\n",
      "3241 : [{'Zulu': 50}]\n",
      "3243 : [{'Zulu': 50}]\n",
      "3268 : [{'Gorra': 10}]\n",
      "3269 : [{'currazy': 10}]\n",
      "3294 : [{'Kathy': 20}]\n",
      "3345 : [{'XIX': 10}]\n",
      "3366 : [{'Italian': 50}, {'Bandamita': 20}]\n",
      "3369 : [{'gotta': 10}, {'thatta': 53}, {'jumpa': 10}]\n",
      "3370 : [{'rolla': 10}, {'bigga': 10}, {'coulda': 10}, {'thatta': 53}]\n",
      "3371 : [{'bricka': 10}, {'buncha': 10}, {'buya': 10}, {'thatta': 53}]\n",
      "3372 : [{'Notta': 10}]\n",
      "3373 : [{'sniffa': 10}, {'busha': 20}]\n",
      "3374 : [{'thatta': 53}]\n",
      "3377 : [{'atta': 10}]\n",
      "3378 : [{'gooda': 10}, {'busha': 20}]\n",
      "3383 : [{'takinga': 10}, {'owna': 10}, {'looka': 10}]\n",
      "3476 : [{'Bandamita': 20}]\n",
      "3478 : [{'Gooda': 10}, {'Councilmanna': 10}, {'walka': 10}, {'fronta': 10}]\n",
      "3479 : [{'twista': 10}]\n",
      "3486 : [{'XX': 10}]\n",
      "3496 : [{'Ryan': 53}]\n",
      "3504 : [{'lapi': 20}, {'lapi': 20}]\n",
      "3519 : [{'Lapid': 10}, {'Aho': 10}]\n",
      "3520 : [{'Australian': 20}]\n",
      "3522 : [{'sich': 50}]\n",
      "3537 : [{'Irish': 20}]\n",
      "3559 : [{'Midas': 10}]\n",
      "3614 : [{'XXI': 10}]\n",
      "3699 : [{'XXII': 10}]\n",
      "3759 : [{'toddlings': 10}]\n",
      "3777 : [{'Pff': 10}]\n",
      "3785 : [{'XXIII': 10}]\n",
      "3800 : [{'Saturdays': 10}]\n",
      "3808 : [{'dunno': 50}]\n",
      "3858 : [{'bloss': 10}]\n",
      "3875 : [{'P.S': 10}]\n",
      "3881 : [{'XXIV': 10}]\n",
      "3936 : [{'Irish': 20}]\n",
      "3941 : [{'XXV': 10}]\n",
      "3991 : [{'Atlantic': 53}]\n",
      "4019 : [{\"dyin'\": 10}]\n",
      "4064 : [{'Plymouth': 10}]\n",
      "4081 : [{'Atlantic': 53}]\n",
      "4088 : [{'Satan': 10}]\n",
      "4103 : [{'XXVI': 10}]\n",
      "4193 : [{'Coun': 10}]\n",
      "4197 : [{'frazzly': 10}]\n",
      "4210 : [{'vitalic': 10}]\n",
      "4215 : [{'XXVII': 10}]\n",
      "4236 : [{'Thompson': 20}]\n",
      "4269 : [{'XXVIII': 10}]\n",
      "4351 : [{'XXIX': 10}]\n",
      "4453 : [{'XXX': 10}]\n",
      "4562 : [{'Rankins': 10}]\n",
      "4569 : [{'XXXI': 10}]\n",
      "4573 : [{\"HISTORY'S\": 10}]\n",
      "4597 : [{'citywards': 10}]\n",
      "4604 : [{'XXXII': 10}]\n",
      "4731 : [{'XXXIII': 10}]\n",
      "4746 : [{'Arrah': 20}, {'anny': 10}]\n",
      "4747 : [{'gorry': 10}]\n",
      "4763 : [{'Sundays': 20}]\n",
      "4814 : [{'Gibraltar': 10}]\n",
      "4825 : [{'horizonward': 10}]\n",
      "4846 : [{'gorra': 10}, {'boonch': 10}]\n",
      "4860 : [{'XXXIV': 10}]\n",
      "4911 : [{'XXXV': 10}]\n",
      "4922 : [{'quo': 20}]\n",
      "4990 : [{'pl': 10}]\n",
      "5036 : [{'XXXVI': 10}]\n",
      "5074 : [{'Arrah': 20}, {'oop': 50}, {'snoopin': 20}, {'varmit': 10}]\n",
      "5076 : [{'snoopin': 20}]\n",
      "5078 : [{'oop': 50}, {'darlin': 20}]\n",
      "5083 : [{'oop': 50}]\n",
      "5088 : [{'XXXVII': 10}]\n",
      "5096 : [{'mys': 10}]\n",
      "5130 : [{'markmanship': 10}]\n",
      "5148 : [{'XXXVIII': 10}]\n",
      "5197 : [{'bullyism': 20}, {'bullyism': 20}]\n",
      "5255 : [{'hmmm': 53}]\n",
      "5261 : [{'XXXIX': 10}]\n",
      "5316 : [{'Pffft': 10}]\n",
      "5333 : [{'Kathy': 20}]\n",
      "5334 : [{'nothin': 20}]\n",
      "5415 : [{'Irving': 10}]\n",
      "5441 : [{'XL': 10}]\n",
      "5487 : [{'Santa': 20}, {'Claus': 20}]\n",
      "5502 : [{'hmmm': 53}]\n",
      "5551 : [{'CHRISTMAS': 10}]\n",
      "5564 : [{'XLI': 10}]\n",
      "5585 : [{'Org': 10}]\n",
      "5613 : [{'Simpk': 10}]\n",
      "5649 : [{'T.N.T': 10}]\n",
      "5670 : [{'hmmm': 53}]\n",
      "5700 : [{'XLII': 10}]\n",
      "5739 : [{'XLIII': 10}]\n",
      "5764 : [{'hmmm': 53}]\n",
      "5777 : [{'Atta': 20}, {'Atta': 20}]\n",
      "5788 : [{'Addison': 20}, {'Addison': 20}]\n",
      "5798 : [{'Patricia': 50}]\n",
      "5799 : [{'Patricia': 50}]\n",
      "5804 : [{'hoosband': 20}]\n",
      "5805 : [{'Ryan': 53}]\n",
      "5817 : [{'Patricia': 50}]\n",
      "5832 : [{'hoosband': 20}]\n",
      "5834 : [{'Goodnight': 10}]\n",
      "5840 : [{'Washington': 53}]\n",
      "5856 : [{'Sirius': 20}]\n",
      "5857 : [{'Fttt': 10}]\n",
      "5858 : [{'Sirius': 20}]\n",
      "5892 : [{'satisfication': 10}]\n",
      "5896 : [{'lassoo': 20}]\n",
      "5900 : [{'politicial': 10}]\n",
      "5904 : [{'lassoo': 20}]\n",
      "5908 : [{'mascarra': 10}]\n",
      "5912 : [{'circut': 10}]\n",
      "5928 : [{'Virgina': 10}]\n",
      "5937 : [{'GUTENBERG': 50}, {'GADSBY': 53}]\n",
      "5940 : [{'47342.txt': 10}, {'47342.zip': 10}]\n",
      "5969 : [{'GUTENBERG': 50}]\n",
      "5982 : [{'1.A': 10}]\n",
      "5985 : [{'trademark/copyright': 10}]\n",
      "5992 : [{'1.E.8': 53}]\n",
      "5994 : [{'1.B': 10}]\n",
      "5999 : [{'1.C': 20}]\n",
      "6002 : [{'1.E': 20}]\n",
      "6004 : [{'1.C': 20}]\n",
      "6005 : [{'PGLAF': 10}]\n",
      "6021 : [{'1.D': 10}]\n",
      "6031 : [{'1.E': 20}]\n",
      "6048 : [{'1.E.2': 10}]\n",
      "6055 : [{'1.E.7': 50}]\n",
      "6057 : [{'1.E.8': 53}, {'1.E.9': 50}]\n",
      "6059 : [{'1.E.3': 10}]\n",
      "6061 : [{'1.E.7': 50}]\n",
      "6067 : [{'1.E.4': 10}]\n",
      "6071 : [{'1.E.5': 10}]\n",
      "6077 : [{'1.E.6': 10}]\n",
      "6081 : [{'ASCII': 20}]\n",
      "6086 : [{'ASCII': 20}]\n",
      "6089 : [{'1.E.7': 50}]\n",
      "6091 : [{'1.E.8': 53}, {'1.E.9': 50}]\n",
      "6093 : [{'1.E.8': 53}]\n",
      "6097 : [{'20%': 10}]\n",
      "6111 : [{'s/he': 10}]\n",
      "6126 : [{'1.E.9': 50}]\n",
      "6130 : [{'LLC': 10}]\n",
      "6133 : [{'1.F': 10}]\n",
      "6135 : [{'1.F.1': 10}]\n",
      "6146 : [{'1.F.2': 10}]\n",
      "6173 : [{'1.F.4': 10}]\n",
      "6178 : [{'1.F.5': 10}]\n",
      "6184 : [{'unenforceability': 10}]\n",
      "6187 : [{'1.F.6': 10}]\n",
      "6221 : [{'non': 10}]\n",
      "6223 : [{'Mississippi': 20}]\n",
      "6224 : [{'EIN': 10}]\n",
      "6229 : [{'Fairbanks': 20}]\n",
      "6230 : [{'PO': 10}, {'Fairbanks': 20}, {'AK': 10}]\n",
      "6239 : [{'Gregory': 10}, {'Newby': 10}]\n",
      "6251 : [{'$1': 10}, {'$5': 10}]\n",
      "6252 : [{'IRS': 10}]\n",
      "6279 : [{'Michael': 10}]\n",
      "6291 : [{'PG': 10}]\n",
      "CPU times: user 273 ms, sys: 24.8 ms, total: 297 ms\n",
      "Wall time: 286 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spell_check_file(\"Full-Gadsby.txt\")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "_Please leave this cell. The marker will write feedback here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please leave this cell.\n",
    "# The marker will fill in your grade here.\n",
    "Q3_GRADE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
